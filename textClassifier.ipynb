{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must run this\n",
    "# list of positive and negative sentences that we will use to populate the positive and negative csv files\n",
    "# make this a list of lists to incorporate the commas \n",
    "# these sentences were generated by chatgpt\n",
    "# if you want to incorporate your own sentences from chatgpt make sure the sentences don't include commas\n",
    "\n",
    "positive_sentences = [\n",
    "    \"I love spending time with my family.\",\n",
    "    \"The sun is shining brightly today.\",\n",
    "    \"I feel so grateful for my supportive friends.\",\n",
    "    \"I enjoy taking long walks in nature.\",\n",
    "    \"Today is going to be a fantastic day!\",\n",
    "    \"I achieved my goal and it feels amazing.\",\n",
    "    \"I am surrounded by positive energy.\",\n",
    "    \"I am proud of my accomplishments.\",\n",
    "    \"I am full of joy and happiness.\",\n",
    "    \"I believe in my abilities and can achieve anything.\",\n",
    "    \"The world is full of endless opportunities.\",\n",
    "    \"I am grateful for all the wonderful experiences in my life.\",\n",
    "    \"I am confident in myself and my abilities.\",\n",
    "    \"Every day brings new opportunities for growth.\",\n",
    "    \"I radiate positivity and attract positivity into my life.\",\n",
    "    \"I am surrounded by love and support.\",\n",
    "    \"I am in control of my own happiness.\",\n",
    "    \"I am worthy of success and abundance.\",\n",
    "    \"I embrace change and see it as an opportunity.\",\n",
    "    \"I have a positive mindset and a positive outlook on life.\",\n",
    "    \"I am capable of achieving greatness.\",\n",
    "    \"I attract positive people and positive experiences.\",\n",
    "    \"I am grateful for all the blessings in my life.\",\n",
    "    \"I am surrounded by beauty and inspiration.\",\n",
    "    \"I am confident in expressing my true self.\",\n",
    "    \"I am becoming the best version of myself.\",\n",
    "    \"I am loved and appreciated.\",\n",
    "    \"I have the power to make a difference.\",\n",
    "    \"I am open to receiving all the good things in life.\",\n",
    "    \"I am resilient and can overcome any challenge.\",\n",
    "    \"I deserve happiness and success.\",\n",
    "    \"I am surrounded by abundance in all areas of my life.\",\n",
    "    \"I am grateful for the simple joys in life.\",\n",
    "    \"I am excited about the possibilities that each day brings.\",\n",
    "    \"I choose to see the good in every situation.\",\n",
    "    \"I am capable of creating a life I love.\",\n",
    "    \"I am deserving of love and respect.\",\n",
    "    \"I am grateful for the opportunities that come my way.\",\n",
    "    \"I am a magnet for positive experiences.\",\n",
    "    \"I am surrounded by peace and tranquility.\",\n",
    "    \"I am confident in my abilities to achieve my goals.\",\n",
    "    \"I am making a positive impact in the world.\",\n",
    "    \"I am filled with gratitude for everything I have.\",\n",
    "    \"I choose to focus on the present moment and find joy in it.\",\n",
    "    \"I am worthy of love success and happiness.\",\n",
    "    \"I am blessed with an abundance of love and support.\",\n",
    "    \"I am constantly growing and evolving as a person.\",\n",
    "    \"I am grateful for the love and kindness in my life.\",\n",
    "    \"I am attracting success and prosperity into my life.\",\n",
    "    \"I am capable of creating positive change in the world.\",\n",
    "]\n",
    "\n",
    "negative_sentences = [\n",
    "    \"I feel overwhelmed and stressed.\",\n",
    "    \"Nothing ever goes right for me.\",\n",
    "    \"I can't seem to catch a break.\",\n",
    "    \"I feel discouraged and unmotivated.\",\n",
    "    \"Everything is falling apart.\",\n",
    "    \"I always make mistakes.\",\n",
    "    \"I feel trapped and helpless.\",\n",
    "    \"I never seem to get what I want.\",\n",
    "    \"I am tired of dealing with constant disappointment.\",\n",
    "    \"Nothing I do is ever good enough.\",\n",
    "    \"I feel like a failure.\",\n",
    "    \"I am surrounded by negativity.\",\n",
    "    \"I can't escape this feeling of sadness.\",\n",
    "    \"I am constantly being criticized and judged.\",\n",
    "    \"I can't see a way out of this situation.\",\n",
    "    \"I am stuck in a cycle of negativity.\",\n",
    "    \"I am losing hope for a better future.\",\n",
    "    \"I can't find any motivation to keep going.\",\n",
    "    \"I am overwhelmed by negativity in my life.\",\n",
    "    \"I can't seem to find any joy or happiness.\",\n",
    "    \"I am surrounded by toxic people.\",\n",
    "    \"I feel like giving up.\",\n",
    "    \"Nothing ever works out for me.\",\n",
    "    \"I am constantly facing obstacles and setbacks.\",\n",
    "    \"I am filled with self-doubt and insecurity.\",\n",
    "    \"I am disappointed in myself.\",\n",
    "    \"I am tired of dealing with this constant negativity.\",\n",
    "    \"I can't see a way to improve my situation.\",\n",
    "    \"I am losing faith in myself.\",\n",
    "    \"I feel rejected and unloved.\",\n",
    "    \"I am surrounded by darkness and despair.\",\n",
    "    \"I can't find any silver lining in this situation.\",\n",
    "    \"I am filled with regret and resentment.\",\n",
    "    \"I am constantly battling with negativity in my mind.\",\n",
    "    \"I feel stuck and powerless.\",\n",
    "    \"I am exhausted from trying to stay positive.\",\n",
    "    \"I am losing sight of my dreams and aspirations.\",\n",
    "    \"I am overwhelmed by negative emotions.\",\n",
    "    \"I am tired of being disappointed all the time.\",\n",
    "    \"I am consumed by negative thoughts.\",\n",
    "    \"I am suffocating in this atmosphere of negativity.\",\n",
    "    \"I am losing hope for a better tomorrow.\",\n",
    "    \"I can't find any meaning or purpose in my life.\",\n",
    "    \"I am constantly surrounded by negativity and drama.\",\n",
    "    \"I am drowning in a sea of negativity.\",\n",
    "    \"I am constantly plagued by self-doubt and fear.\",\n",
    "    \"I am filled with resentment and bitterness.\",\n",
    "    \"I am tired of fighting this never-ending battle.\",\n",
    "    \"I can't escape this feeling of emptiness.\",\n",
    "    \"I am losing my sense of self-worth.\",\n",
    "    \"I am trapped in a cycle of negativity and self-destruction.\",\n",
    "    \"I can't see any way to turn things around.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating positive and negative files \n",
    "\n",
    "import csv \n",
    "\n",
    "positive_text = 'positive.csv'\n",
    "negative_text = 'negative.csv'\n",
    "\n",
    "# populate the files\n",
    "\n",
    "# do i need positive_file ? \n",
    "\n",
    "header = \"Sentences\" \n",
    "\n",
    "positive_file = open(positive_text, 'w')\n",
    "with open(negative_text, 'w') as negative_file: # opening file # ** should fix this from neg to pos but it still works, why does it work?\n",
    "    positive_file.write(f'{header}\\n') # adding header\n",
    "    for sentences in positive_sentences: # adding each sentences to csv file\n",
    "        positive_file.write(f'{sentences}\\n') \n",
    "\n",
    "\n",
    "negative_file = open(positive_text, 'w') \n",
    "with open(negative_text, 'w') as negative_file:\n",
    "    negative_file.write(f'{header}\\n')\n",
    "    for sentences in negative_sentences:\n",
    "        negative_file.write(f'{sentences}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apparently you have to run this too\n",
    "# read and print both csv files\n",
    "\n",
    "with open(positive_text, 'r') as positive_file:\n",
    "    csv.reader(positive_file)\n",
    "    # for row in csv_reader: # uncomment to print\n",
    "    #     print(row)\n",
    "\n",
    "with open(negative_text, 'r') as negative_file:\n",
    "    csv.reader(negative_file)\n",
    "    # for row in csv_reader: # uncomment to print\n",
    "    #     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# file truncator \n",
    "# split the file into 80%, 20%, etc, then write it into its according file \n",
    "# use this to split the data into writing and testing csv files\n",
    "\n",
    "'''\n",
    "Plan for organizing data for ease of user use:\n",
    "3 data sets: \n",
    "    1) positive sentenecs\n",
    "    2) negative sentences \n",
    "        -1 and 2 will both be generated by chatgpt, user can choose their own groups instead of positive or ngeative, itll be something like hungry or not hungry; anything with 2 groups\n",
    "            - in the future should allow for more than 2 groups.\n",
    "    3) test the model and allow the user to input a sentence and model will predict the according group\n",
    "\n",
    "# files we actually use: positive, negative (these are to train the model)  , model.csv is what the model gets tested on. we don't need to do anything on test_predictions.csv as it just takes model.csv and labels it\n",
    "'''\n",
    "\n",
    "train_set_text = 'train.csv' \n",
    "model_set_text = 'model.csv'\n",
    "#no i dont need thse\n",
    "# train_set_file = '' # why do i need to open it as this?, and can i get rid of these and just pass in random files to be stored temporarily \n",
    "# model_set_file = ''\n",
    "\n",
    "# this clears both files. We do this so that when we append the new data we don't append it with previously ran data (ie if you ran this multiple times it wouldn't be hundreds of sentences)\n",
    "with open(train_set_text, 'w') as train_set_file:\n",
    "    pass\n",
    "with open(model_set_text, 'w') as model_set_file:\n",
    "    pass\n",
    "\n",
    "\n",
    "def truncator(readText, readFile, writeText, writeFile, percentage, beginningBool):\n",
    "    with open(readText, 'r') as readFile:\n",
    "        stored_lines = readFile.readlines()\n",
    "\n",
    "    with open(writeText, 'a') as writeFile: # to append use 'a'\n",
    "        if(beginningBool):\n",
    "            writeFile.writelines(stored_lines[:int(len(stored_lines)*percentage*0.01)])\n",
    "        else:\n",
    "            writeFile.writelines(stored_lines[int(len(stored_lines)*percentage*0.01):])\n",
    "\n",
    "# place 80% of negative text and positive text into test.csv\n",
    "truncator(positive_text, positive_file, train_set_text, train_set_file, 80, True) # this is getting overidden, use 'a' when writing text to append\n",
    "truncator(negative_text, negative_file, train_set_text, train_set_file, 80, True) \n",
    "\n",
    "# place 20% of the remaining text in the model_set so we can test it on that \n",
    "truncator(positive_text, positive_file, model_set_text, model_set_file, 80, False)\n",
    "truncator(negative_text, negative_file, model_set_text, model_set_file, 80, False)\n",
    "\n",
    "# new, should test later\n",
    "# since we aren't using train_set_text and we instead want 80% of positive and negative text, we pass it as a the read and write file\n",
    "# now we are truncating the file to 80% of it\n",
    "# But once we do that we have to make sure that this does not run more than 1 time and we also have to make sure that we run it after model_set_file\n",
    "# I don't think we have to do this because we don't want to split the data as 80:20 anymore, since our goal is to let the user put in whatever data they wwant from chatgpt\n",
    "# ...then take that data and test it on some more data. Plus we should adapt this so that they can have more than 2 data classes(positive, negative)\n",
    "# truncator(positive_text, positive_file, train_set_text, train_set_file, 80, True) # this is getting overidden, use 'a' when writing text to append\n",
    "# truncator(negative_text, negative_file, train_set_text, train_set_file, 80, True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStep 2) Train a Naive Bayes classifier (Program 1)\\n\\n2.a) Read in training set from the train.csv file \\n\\n2.b) Calculate the prior probabilities for both classes using the training set\\n\\n2.b) Calculate the conditional probability of each unique word in the training set given a class. Compute these conditional probabilities for each class. \\n\\nSlide 45 on day 4 slidedeck\\n\\n------\\nApproach\\n\\nlaplace smoothing \\nP(w|c) = (c(w,c)+k) / count(c) + |v|\\ncount() count function, w is the amount of times the word w appears, c is the number of examples, k is the smoothing parameter\\n\\nOur situation\\n\\nP(w|c) = (c(w,c)+k) / count(c) + |v|\\nw = the word, c = positive or negative sentence group, c on denominator is the number of words in total (in that group and not unique) , |v| is the number of unique words we have in total \\n(w+c) + 1 /   + |v|\\n(do we always add only 1?)\\n\\n\\np(w|c) : w = the word, c = positive or negative sentence group\\n\\nnumerator\\ncount(w+c) + 1 : w,c+1  count(w,c) is the number of times that word appears in that group, c, 1 is just the smoothing (can the smoothing amount be changed to a value greater than 1?)\\n\\ndenominator \\ncount(c) + |v| : c+v    c is the number of words in total in class (in that group and not unique) , |v| is the number of unique words we have in total entire dictionary. v for vocabulary\\n\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#notes\n",
    "'''\n",
    "Step 2) Train a Naive Bayes classifier (Program 1)\n",
    "\n",
    "2.a) Read in training set from the train.csv file \n",
    "\n",
    "2.b) Calculate the prior probabilities for both classes using the training set\n",
    "\n",
    "2.b) Calculate the conditional probability of each unique word in the training set given a class. Compute these conditional probabilities for each class. \n",
    "\n",
    "Slide 45 on day 4 slidedeck\n",
    "\n",
    "------\n",
    "Approach\n",
    "\n",
    "laplace smoothing \n",
    "P(w|c) = (c(w,c)+k) / count(c) + |v|\n",
    "count() count function, w is the amount of times the word w appears, c is the number of examples, k is the smoothing parameter\n",
    "\n",
    "Our situation\n",
    "\n",
    "P(w|c) = (c(w,c)+k) / count(c) + |v|\n",
    "w = the word, c = positive or negative sentence group, c on denominator is the number of words in total (in that group and not unique) , |v| is the number of unique words we have in total \n",
    "(w+c) + 1 /   + |v|\n",
    "(do we always add only 1?)\n",
    "\n",
    "\n",
    "p(w|c) : w = the word, c = positive or negative sentence group\n",
    "\n",
    "numerator\n",
    "count(w+c) + 1 : w,c+1  count(w,c) is the number of times that word appears in that group, c, 1 is just the smoothing (can the smoothing amount be changed to a value greater than 1?)\n",
    "\n",
    "denominator \n",
    "count(c) + |v| : c+v    c is the number of words in total in class (in that group and not unique) , |v| is the number of unique words we have in total entire dictionary. v for vocabulary\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# step 2\n",
    "# define a method for each part of the equation \n",
    "# then have a final method that calls each part of the equation and add divide to get the final val which is the likelihood probability \n",
    "\n",
    "# step 3 figure out a datastructure to fit the data in. maybe hashmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO important\n",
    "# get rid of periods\n",
    "# try to see if you can get rid of commas in csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# step 2\n",
    "# pip install pandas # uncomment this to install, or run in terminal\n",
    "import pandas as pd \n",
    "\n",
    "# reading the positive and negative csv files again\n",
    "\n",
    "positive = pd.read_csv(\"positive.csv\")\n",
    "negative = pd.read_csv(\"negative.csv\")\n",
    "\n",
    "# split into list of sentences\n",
    "    # -> probably should give a proper header later\n",
    "\n",
    "# print(positive)\n",
    "\n",
    "\n",
    "positive = positive[header].str.split()\n",
    "negative = negative[header].str.split()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0033112582781456954\n"
     ]
    }
   ],
   "source": [
    "# no longer used\n",
    "\n",
    "# numerator: count(w,c) | add 1 in the p(w|c) function\n",
    "    # -> rename the parameters\n",
    "def numerator(w,c): # w is word, c is a pandas Series\n",
    "    count = 0\n",
    "    for i in c:\n",
    "        if i == w:\n",
    "            count += 1\n",
    "    return count \n",
    "import string\n",
    "\n",
    "def denominator(group):\n",
    "    uniqueWords = set() # ?store as a set instead of dictionary\n",
    "    wordsInGroup = 0 \n",
    "    combinedList = [element for sublist in (positive) for element in sublist] # doing it in the same line makes a list of lists again\n",
    "    combinedList += [element for sublist in (negative) for element in sublist]\n",
    "    for words in group:\n",
    "        wordsInGroup += 1\n",
    "    for words in combinedList: # unique words in both positive and negative \n",
    "        words = words.translate(words.maketrans('', '', string.punctuation)).lower() # make lowercase and remove punctuation\n",
    "        if words not in uniqueWords:\n",
    "            uniqueWords.add(words)\n",
    "    return wordsInGroup + len(uniqueWords) # count(c) + |v|\n",
    "        \n",
    "# likelihood equation with laplace smoothing\n",
    "# instead of \"like \" and positive we should pass in a parameter to p like p(w,c) again\n",
    "def p(word,group):\n",
    "    # return str( round ((numerator(word, group) + 1) / denominator(group)*100 ,2) ) # place into % format # messes with the testing phase when multiplying nums\n",
    "    return (numerator(word, group) + 1) / denominator(group) # reg format\n",
    "# -> make it so that v doesnt have to run each time, have it loop once\n",
    "\n",
    "# testing outputs\n",
    "print(p(\"like\", positive))\n",
    "\n",
    "\n",
    "\n",
    "# ***** to revise make a dictionary with {word, amount of times that word appears} that way you only need to loop through it once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no longer used\n",
    "test_predictions = 'test_predictions.csv'  # this csv file will store the sentence along with its according group \n",
    "\n",
    "headers = [\"sentence\", \"group\"]\n",
    "\n",
    "with open(test_predictions, 'w', newline='') as file:  # put in a header for the predictions file\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(headers)\n",
    "\n",
    "for sentences in model: \n",
    "    positiveLikeliness = 1\n",
    "    negativeLikeliness = 1\n",
    "    for words in sentences:\n",
    "        positiveLikeliness *= p(words, positive)\n",
    "        negativeLikeliness *= p(words, negative)\n",
    "        print(\"neg: \",negativeLikeliness)\n",
    "        print(\"pos: \",positiveLikeliness)\n",
    "\n",
    "    with open(test_predictions, 'a') as test_file:\n",
    "        if positiveLikeliness > negativeLikeliness:\n",
    "                test_file.write(\"positive: \"+' '.join(sentences)+'\\n') \n",
    "                # positive_file.write(sentences,\"Positive\") \n",
    "        else:\n",
    "            test_file.write(\"negative: \"+' '.join(sentences)+'\\n') \n",
    "\n",
    "    #         test_predictions.write(sentences,\"negative\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Divider\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' more steps and notes\n",
    "Revise steps: \n",
    "\n",
    "1) sort files, probably should remove 10 lines from both positive and negative csv files\n",
    "\n",
    "2) use def functions but instead of making it a function that repeats multiple times have it run one time and then take \n",
    "\n",
    "Have a function that runs one time \n",
    "the function should be able to take in each word and calculate the probability for EACH class\n",
    "thus, it should run leng(wordsInBothTestFiles)*2 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2.5) run a for loop that runs each word along with each class(pos or neg) \n",
    "    take the probability of each word and store it into a dictionary (word, probability)\n",
    "\n",
    "3) call each word that is found from the dicitionary \n",
    "\n",
    "\n",
    "* keep in mind:\n",
    "\n",
    "    dicitonary will be (word, tuple->('p or n here', probability ))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) remove 10 files from neg and positive csv file so that it is 80% of the training data\n",
    "# store it in a new file\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# without using pd it formats the file incorrectly and prevents it from being used in the rest of our code\n",
    "# don't use this\n",
    "# def removeLastTenLinesWithoutPD(input_file):\n",
    "#     with open(input_file, 'r') as file:\n",
    "#         reader = csv.reader(file)\n",
    "#         lines = list(reader)\n",
    "#         fileWithRemovedLines = lines[:-10] # \n",
    "#         # fileWithRemovedLines = (lines[:int(len(lines)*20*0.01)]) # this should be 20% of the lines but test this later to see if its actually true # this didn't work the same\n",
    "#         return fileWithRemovedLines\n",
    "# --\n",
    "\n",
    "def removeLastTenLines(input_file):\n",
    "    input_file = pd.read_csv(input_file)  \n",
    "    fileWithRemovedLines = input_file[:-10] # instead of manually inputting 20% of the lines( 10 lines), lets remove 20% of the lines\n",
    "    # fileWithRemovedLines = (input_file[:int(len(input_file)*20*0.01)]) \n",
    "    return fileWithRemovedLines\n",
    "\n",
    "# 20% of the lines\n",
    "\n",
    "\n",
    "    \n",
    "positive_training = removeLastTenLines('positive.csv') # this is now 80% of the training set \n",
    "negative_training = removeLastTenLines('negative.csv')\n",
    "    \n",
    "# print(positive_training) # not sure why this is only 38 lines while the other is 40\n",
    "# print(negative_training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "42\n",
      "POSITIVE\n",
      "key 1\n",
      "\n",
      "I 0.13523131672597866\n",
      "\n",
      "love 0.014234875444839857\n",
      "\n",
      "spending 0.0071174377224199285\n",
      "\n",
      "time 0.0071174377224199285\n",
      "\n",
      "with 0.0071174377224199285\n",
      "\n",
      "my 0.0498220640569395\n",
      "\n",
      "family. 0.0071174377224199285\n",
      "\n",
      "The 0.010676156583629894\n",
      "\n",
      "sun 0.0071174377224199285\n",
      "\n",
      "is 0.014234875444839857\n",
      "\n",
      "shining 0.0071174377224199285\n",
      "\n",
      "brightly 0.0071174377224199285\n",
      "\n",
      "today. 0.0071174377224199285\n",
      "\n",
      "feel 0.0071174377224199285\n",
      "\n",
      "so 0.0071174377224199285\n",
      "\n",
      "grateful 0.021352313167259787\n",
      "\n",
      "for 0.028469750889679714\n",
      "\n",
      "supportive 0.0071174377224199285\n",
      "\n",
      "friends. 0.0071174377224199285\n",
      "\n",
      "enjoy 0.0071174377224199285\n",
      "\n",
      "taking 0.0071174377224199285\n",
      "\n",
      "long 0.0071174377224199285\n",
      "\n",
      "walks 0.0071174377224199285\n",
      "\n",
      "in 0.042704626334519574\n",
      "\n",
      "nature. 0.0071174377224199285\n",
      "\n",
      "Today 0.0071174377224199285\n",
      "\n",
      "going 0.0071174377224199285\n",
      "\n",
      "to 0.017793594306049824\n",
      "\n",
      "be 0.0071174377224199285\n",
      "\n",
      "a 0.02491103202846975\n",
      "\n",
      "fantastic 0.0071174377224199285\n",
      "\n",
      "day! 0.0071174377224199285\n",
      "\n",
      "achieved 0.0071174377224199285\n",
      "\n",
      "goal 0.0071174377224199285\n",
      "\n",
      "and 0.060498220640569395\n",
      "\n",
      "it 0.010676156583629894\n",
      "\n",
      "feels 0.0071174377224199285\n",
      "\n",
      "amazing. 0.0071174377224199285\n",
      "\n",
      "am 0.08896797153024912\n",
      "\n",
      "surrounded 0.021352313167259787\n",
      "\n",
      "by 0.021352313167259787\n",
      "\n",
      "positive 0.02491103202846975\n",
      "\n",
      "energy. 0.0071174377224199285\n",
      "\n",
      "proud 0.0071174377224199285\n",
      "\n",
      "of 0.03914590747330961\n",
      "\n",
      "accomplishments. 0.0071174377224199285\n",
      "\n",
      "full 0.010676156583629894\n",
      "\n",
      "joy 0.0071174377224199285\n",
      "\n",
      "happiness. 0.010676156583629894\n",
      "\n",
      "believe 0.0071174377224199285\n",
      "\n",
      "abilities 0.0071174377224199285\n",
      "\n",
      "can 0.010676156583629894\n",
      "\n",
      "achieve 0.0071174377224199285\n",
      "\n",
      "anything. 0.0071174377224199285\n",
      "\n",
      "world 0.0071174377224199285\n",
      "\n",
      "endless 0.0071174377224199285\n",
      "\n",
      "opportunities. 0.0071174377224199285\n",
      "\n",
      "all 0.017793594306049824\n",
      "\n",
      "the 0.03558718861209965\n",
      "\n",
      "wonderful 0.0071174377224199285\n",
      "\n",
      "experiences 0.0071174377224199285\n",
      "\n",
      "life. 0.028469750889679714\n",
      "\n",
      "confident 0.010676156583629894\n",
      "\n",
      "myself 0.0071174377224199285\n",
      "\n",
      "abilities. 0.0071174377224199285\n",
      "\n",
      "Every 0.0071174377224199285\n",
      "\n",
      "day 0.010676156583629894\n",
      "\n",
      "brings 0.0071174377224199285\n",
      "\n",
      "new 0.0071174377224199285\n",
      "\n",
      "opportunities 0.010676156583629894\n",
      "\n",
      "growth. 0.0071174377224199285\n",
      "\n",
      "radiate 0.0071174377224199285\n",
      "\n",
      "positivity 0.010676156583629894\n",
      "\n",
      "attract 0.010676156583629894\n",
      "\n",
      "into 0.0071174377224199285\n",
      "\n",
      "support. 0.0071174377224199285\n",
      "\n",
      "control 0.0071174377224199285\n",
      "\n",
      "own 0.0071174377224199285\n",
      "\n",
      "worthy 0.0071174377224199285\n",
      "\n",
      "success 0.0071174377224199285\n",
      "\n",
      "abundance. 0.0071174377224199285\n",
      "\n",
      "embrace 0.0071174377224199285\n",
      "\n",
      "change 0.0071174377224199285\n",
      "\n",
      "see 0.010676156583629894\n",
      "\n",
      "as 0.0071174377224199285\n",
      "\n",
      "an 0.0071174377224199285\n",
      "\n",
      "opportunity. 0.0071174377224199285\n",
      "\n",
      "have 0.010676156583629894\n",
      "\n",
      "mindset 0.0071174377224199285\n",
      "\n",
      "outlook 0.0071174377224199285\n",
      "\n",
      "on 0.0071174377224199285\n",
      "\n",
      "capable 0.010676156583629894\n",
      "\n",
      "achieving 0.0071174377224199285\n",
      "\n",
      "greatness. 0.0071174377224199285\n",
      "\n",
      "people 0.0071174377224199285\n",
      "\n",
      "experiences. 0.010676156583629894\n",
      "\n",
      "blessings 0.0071174377224199285\n",
      "\n",
      "beauty 0.0071174377224199285\n",
      "\n",
      "inspiration. 0.0071174377224199285\n",
      "\n",
      "expressing 0.0071174377224199285\n",
      "\n",
      "true 0.0071174377224199285\n",
      "\n",
      "self. 0.0071174377224199285\n",
      "\n",
      "becoming 0.0071174377224199285\n",
      "\n",
      "best 0.0071174377224199285\n",
      "\n",
      "version 0.0071174377224199285\n",
      "\n",
      "myself. 0.0071174377224199285\n",
      "\n",
      "loved 0.0071174377224199285\n",
      "\n",
      "appreciated. 0.0071174377224199285\n",
      "\n",
      "power 0.0071174377224199285\n",
      "\n",
      "make 0.0071174377224199285\n",
      "\n",
      "difference. 0.0071174377224199285\n",
      "\n",
      "open 0.0071174377224199285\n",
      "\n",
      "receiving 0.0071174377224199285\n",
      "\n",
      "good 0.010676156583629894\n",
      "\n",
      "things 0.0071174377224199285\n",
      "\n",
      "resilient 0.0071174377224199285\n",
      "\n",
      "overcome 0.0071174377224199285\n",
      "\n",
      "any 0.0071174377224199285\n",
      "\n",
      "challenge. 0.0071174377224199285\n",
      "\n",
      "deserve 0.0071174377224199285\n",
      "\n",
      "happiness 0.0071174377224199285\n",
      "\n",
      "success. 0.0071174377224199285\n",
      "\n",
      "abundance 0.0071174377224199285\n",
      "\n",
      "areas 0.0071174377224199285\n",
      "\n",
      "simple 0.0071174377224199285\n",
      "\n",
      "joys 0.0071174377224199285\n",
      "\n",
      "excited 0.0071174377224199285\n",
      "\n",
      "about 0.0071174377224199285\n",
      "\n",
      "possibilities 0.0071174377224199285\n",
      "\n",
      "that 0.010676156583629894\n",
      "\n",
      "each 0.0071174377224199285\n",
      "\n",
      "brings. 0.0071174377224199285\n",
      "\n",
      "choose 0.0071174377224199285\n",
      "\n",
      "every 0.0071174377224199285\n",
      "\n",
      "situation. 0.0071174377224199285\n",
      "\n",
      "creating 0.0071174377224199285\n",
      "\n",
      "life 0.0071174377224199285\n",
      "\n",
      "love. 0.0071174377224199285\n",
      "\n",
      "deserving 0.0071174377224199285\n",
      "\n",
      "respect. 0.0071174377224199285\n",
      "\n",
      "come 0.0071174377224199285\n",
      "\n",
      "way. 0.0071174377224199285\n",
      "\n",
      "magnet 0.0071174377224199285\n",
      "\n",
      "peace 0.0071174377224199285\n",
      "\n",
      "tranquility. 0.0071174377224199285\n",
      "\n",
      "NEGATIVE\n",
      "key 0\n",
      "\n",
      "I 0.14487632508833923\n",
      "\n",
      "feel 0.028268551236749116\n",
      "\n",
      "overwhelmed 0.014134275618374558\n",
      "\n",
      "and 0.04240282685512368\n",
      "\n",
      "stressed. 0.007067137809187279\n",
      "\n",
      "Nothing 0.014134275618374558\n",
      "\n",
      "ever 0.014134275618374558\n",
      "\n",
      "goes 0.007067137809187279\n",
      "\n",
      "right 0.007067137809187279\n",
      "\n",
      "for 0.0176678445229682\n",
      "\n",
      "me. 0.01060070671378092\n",
      "\n",
      "can't 0.028268551236749116\n",
      "\n",
      "seem 0.014134275618374558\n",
      "\n",
      "to 0.024734982332155476\n",
      "\n",
      "catch 0.007067137809187279\n",
      "\n",
      "a 0.028268551236749116\n",
      "\n",
      "break. 0.007067137809187279\n",
      "\n",
      "discouraged 0.007067137809187279\n",
      "\n",
      "unmotivated. 0.007067137809187279\n",
      "\n",
      "Everything 0.007067137809187279\n",
      "\n",
      "is 0.01060070671378092\n",
      "\n",
      "falling 0.007067137809187279\n",
      "\n",
      "apart. 0.007067137809187279\n",
      "\n",
      "always 0.007067137809187279\n",
      "\n",
      "make 0.007067137809187279\n",
      "\n",
      "mistakes. 0.007067137809187279\n",
      "\n",
      "trapped 0.007067137809187279\n",
      "\n",
      "helpless. 0.007067137809187279\n",
      "\n",
      "never 0.007067137809187279\n",
      "\n",
      "get 0.007067137809187279\n",
      "\n",
      "what 0.007067137809187279\n",
      "\n",
      "want. 0.007067137809187279\n",
      "\n",
      "am 0.0812720848056537\n",
      "\n",
      "tired 0.014134275618374558\n",
      "\n",
      "of 0.03180212014134275\n",
      "\n",
      "dealing 0.01060070671378092\n",
      "\n",
      "with 0.02120141342756184\n",
      "\n",
      "constant 0.01060070671378092\n",
      "\n",
      "disappointment. 0.007067137809187279\n",
      "\n",
      "do 0.007067137809187279\n",
      "\n",
      "good 0.007067137809187279\n",
      "\n",
      "enough. 0.007067137809187279\n",
      "\n",
      "like 0.01060070671378092\n",
      "\n",
      "failure. 0.007067137809187279\n",
      "\n",
      "surrounded 0.014134275618374558\n",
      "\n",
      "by 0.024734982332155476\n",
      "\n",
      "negativity. 0.0176678445229682\n",
      "\n",
      "escape 0.007067137809187279\n",
      "\n",
      "this 0.02120141342756184\n",
      "\n",
      "feeling 0.007067137809187279\n",
      "\n",
      "sadness. 0.007067137809187279\n",
      "\n",
      "constantly 0.014134275618374558\n",
      "\n",
      "being 0.01060070671378092\n",
      "\n",
      "criticized 0.007067137809187279\n",
      "\n",
      "judged. 0.007067137809187279\n",
      "\n",
      "see 0.01060070671378092\n",
      "\n",
      "way 0.01060070671378092\n",
      "\n",
      "out 0.01060070671378092\n",
      "\n",
      "situation. 0.014134275618374558\n",
      "\n",
      "stuck 0.01060070671378092\n",
      "\n",
      "in 0.028268551236749116\n",
      "\n",
      "cycle 0.007067137809187279\n",
      "\n",
      "losing 0.0176678445229682\n",
      "\n",
      "hope 0.01060070671378092\n",
      "\n",
      "better 0.01060070671378092\n",
      "\n",
      "future. 0.007067137809187279\n",
      "\n",
      "find 0.014134275618374558\n",
      "\n",
      "any 0.014134275618374558\n",
      "\n",
      "motivation 0.007067137809187279\n",
      "\n",
      "keep 0.007067137809187279\n",
      "\n",
      "going. 0.007067137809187279\n",
      "\n",
      "negativity 0.01060070671378092\n",
      "\n",
      "my 0.0176678445229682\n",
      "\n",
      "life. 0.007067137809187279\n",
      "\n",
      "joy 0.007067137809187279\n",
      "\n",
      "or 0.007067137809187279\n",
      "\n",
      "happiness. 0.007067137809187279\n",
      "\n",
      "toxic 0.007067137809187279\n",
      "\n",
      "people. 0.007067137809187279\n",
      "\n",
      "giving 0.007067137809187279\n",
      "\n",
      "up. 0.007067137809187279\n",
      "\n",
      "works 0.007067137809187279\n",
      "\n",
      "facing 0.007067137809187279\n",
      "\n",
      "obstacles 0.007067137809187279\n",
      "\n",
      "setbacks. 0.007067137809187279\n",
      "\n",
      "filled 0.01060070671378092\n",
      "\n",
      "self-doubt 0.007067137809187279\n",
      "\n",
      "insecurity. 0.007067137809187279\n",
      "\n",
      "disappointed 0.01060070671378092\n",
      "\n",
      "myself. 0.01060070671378092\n",
      "\n",
      "improve 0.007067137809187279\n",
      "\n",
      "faith 0.007067137809187279\n",
      "\n",
      "rejected 0.007067137809187279\n",
      "\n",
      "unloved. 0.007067137809187279\n",
      "\n",
      "darkness 0.007067137809187279\n",
      "\n",
      "despair. 0.007067137809187279\n",
      "\n",
      "silver 0.007067137809187279\n",
      "\n",
      "lining 0.007067137809187279\n",
      "\n",
      "regret 0.007067137809187279\n",
      "\n",
      "resentment. 0.007067137809187279\n",
      "\n",
      "battling 0.007067137809187279\n",
      "\n",
      "mind. 0.007067137809187279\n",
      "\n",
      "powerless. 0.007067137809187279\n",
      "\n",
      "exhausted 0.007067137809187279\n",
      "\n",
      "from 0.007067137809187279\n",
      "\n",
      "trying 0.007067137809187279\n",
      "\n",
      "stay 0.007067137809187279\n",
      "\n",
      "positive. 0.007067137809187279\n",
      "\n",
      "sight 0.007067137809187279\n",
      "\n",
      "dreams 0.007067137809187279\n",
      "\n",
      "aspirations. 0.007067137809187279\n",
      "\n",
      "negative 0.01060070671378092\n",
      "\n",
      "emotions. 0.007067137809187279\n",
      "\n",
      "all 0.007067137809187279\n",
      "\n",
      "the 0.007067137809187279\n",
      "\n",
      "time. 0.007067137809187279\n",
      "\n",
      "consumed 0.007067137809187279\n",
      "\n",
      "thoughts. 0.007067137809187279\n",
      "\n",
      "suffocating 0.007067137809187279\n",
      "\n",
      "atmosphere 0.007067137809187279\n",
      "\n",
      "tomorrow. 0.007067137809187279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) revising the functions\n",
    "\n",
    "# note: p(c) and p(j) will always be 1/2 in our scenario because we are always splitting the data evenly in half \n",
    "\n",
    "# creating the dictionary\n",
    "# make it a dictionary inside of a dictionary instead of a tuple \n",
    "\n",
    "# moved dictionary to step 2.5#  # dictionary to store conditional probabilities\n",
    "# conditionalProbabilitiesPos = {'key':{'group',1}} # how do i make this empty?\n",
    "\n",
    "\n",
    "positive = positive_training[header].str.split()\n",
    "negative = negative_training[header].str.split()\n",
    "\n",
    "\n",
    "##################\n",
    "\n",
    "\n",
    "\n",
    "# step 2 revised\n",
    "\n",
    "# steps: \n",
    "\n",
    "'''\n",
    "\n",
    "numerator\n",
    "count(w+c) + 1 : w,c+1  count(w,c) is the number of times that word appears in that group, c, 1 is just the smoothing (can the smoothing amount be changed to a value greater than 1?)\n",
    "\n",
    "denominator \n",
    "count(c) + |v| : c+v    c is the number of words in total in class (in that group and not unique) , |v| is the number of unique words we have in total entire dictionary. v for vocabulary\n",
    "\n",
    "'''\n",
    "\n",
    "# make a hashmap with {words, count}\n",
    "# numerator: to get \n",
    "\n",
    "\n",
    "# import pandas as pd \n",
    "\n",
    "# reading the positive and negative csv files again\n",
    "\n",
    "# positive = pd.read_csv(\"positive.csv\")\n",
    "# negative = pd.read_csv(\"negative.csv\")\n",
    "\n",
    "# split into list of sentences\n",
    "    # -> probably should give a proper header later\n",
    "\n",
    "# print(positive)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# numerator: count(w,c) | add 1 in the p(w|c) function\n",
    "    # -> rename the parameters\n",
    "    # *** this is figuring out how many times the word appears in the entire positive file\n",
    "    # *** therefore this also only needs to run once for each word in each group which we did.\n",
    "def numerator(w,c): # w is word, c is group pos or neg\n",
    "    count = 0\n",
    "    # loopCounter = 0\n",
    "    for sentence in c: # this is actually comparing a list of words to 1 words, which is causing it to always output 0\n",
    "        for word in sentence:\n",
    "            # print(\"word getting compared: \",word,\"==\",w) # now this is working properly\n",
    "            if word == w:\n",
    "                count += 1\n",
    "        # loopCounter += 1\n",
    "        # for testing purposes\n",
    "        # print('this is the p(w,c) part:',count)\n",
    "        # print(\"this looped\",loopCounter,'times')\n",
    "    return count # this was in the wrong loop causing the loop to end early\n",
    "\n",
    "def denominator(group):\n",
    "    uniqueWords = set() # ?store as a set instead of dictionary\n",
    "    wordsInGroup = 0 \n",
    "    combinedList = [element for sublist in (positive) for element in sublist] # doing it in the same line makes a list of lists again\n",
    "    combinedList += [element for sublist in (negative) for element in sublist]\n",
    "    for words in group:\n",
    "        wordsInGroup += 1\n",
    "    for words in combinedList: # unique words in both positive and negative \n",
    "        if words not in uniqueWords:\n",
    "            uniqueWords.add(words)\n",
    "    return wordsInGroup + len(uniqueWords) # count(c) + |v|\n",
    "        \n",
    "    \n",
    "\n",
    "# likelihood equation with laplace smoothing\n",
    "# instead of \"like \" and positive we should pass in a parameter to p like p(w,c) again\n",
    "def p(word,group):\n",
    "    # return str( round ((numerator(word, group) + 1) / denominator(group)*100 ,2) ) # place into % format\n",
    "    # testing purposes:\n",
    "    # print('numerator:',numerator(word,group))\n",
    "    # print('denomenator:',denominator(group))\n",
    "    # print(\"word:\",word)\n",
    "    # delete when done\n",
    "    return (numerator(word, group) + 1) / denominator(group) # reg format\n",
    "\n",
    "# -> make it so that v doesnt have to run each time, have it loop once\n",
    "\n",
    "############ running it once and putting it all into a dictionary (conditionalProbabilitiesPos)\n",
    "\n",
    "\n",
    "\n",
    "# step 2.5 -\n",
    "\n",
    "# conditionalProbabilitiesPos = {'key':{'group',1}} # no longer need this because now we're going to be sorting it in separate groups \n",
    "conditionalProbabilitiesPos = {'key': 1}\n",
    "\n",
    "for sentences in positive:  # only positive for now  #,negative: \n",
    "    positiveLikeliness = 1\n",
    "    for words in sentences:\n",
    "        if words not in conditionalProbabilitiesPos:\n",
    "            positiveLikeliness = p(words, positive)  # this gives us the probability, we already know that all these words are in the positive group so now we can put everything into a dictionary\n",
    "            conditionalProbabilitiesPos.update({words : positiveLikeliness}) # class P for positive  #**** might need to reset the dictionary each time for each sentence?\n",
    "\n",
    "\n",
    "# ---------\n",
    "# this won't work because every word is already in the dictionary\n",
    "# I can either add another if statement say if the words along with the class negative is not in the dictionary then add it \n",
    "# or \n",
    "# i can run the same loop for negative on a different set ** simplest solution, not very efficient  ** probably will do this\n",
    "\n",
    "# conditionalProbabilitiesNeg = {'key':{'group',1}} # making a seperate dictionary to store negative words\n",
    "conditionalProbabilitiesNeg = {'key': 0} # making a seperate dictionary to store negative words\n",
    "\n",
    "uniqueWords = 0 # for testing purposes\n",
    "totalWords = 0\n",
    "\n",
    "for sentences in negative:  # samething for negative\n",
    "    negativeLikeliness = 1 # this does nothing now \n",
    "    for words in sentences:\n",
    "        if words not in conditionalProbabilitiesNeg: # if the word is already in the dictionary we don't need to calculate it again\n",
    "            # trying to find issue\n",
    "            # uniqueWords += 1\n",
    "            # print(words)\n",
    "            # print(p(words,negative))\n",
    "            # delete when done\n",
    "            negativeLikeliness = p(words, negative)   # we should not multiply this \n",
    "\n",
    "            conditionalProbabilitiesNeg.update({words : negativeLikeliness})\n",
    "    totalWords +=1\n",
    "\n",
    "print(uniqueWords)\n",
    "print(totalWords)\n",
    "\n",
    "\n",
    "# ---------\n",
    "\n",
    "\n",
    "print(\"POSITIVE\")\n",
    "for key, value in conditionalProbabilitiesPos.items():\n",
    "    # print(f\"Word:               {key}\")\n",
    "    # print(f\"Class & Likeliness: {value}\")\n",
    "    print(f\"{key} {value}\\n\")\n",
    "\n",
    "\n",
    "print(\"NEGATIVE\")   \n",
    "for key, value in conditionalProbabilitiesNeg.items():\n",
    "    print(f\"{key} {value}\\n\")\n",
    "\n",
    "        \n",
    "        # issues: and punctuation is not getting removed \n",
    "        # fixed issues: numerator is changing\n",
    "        # denominator is changing. its always 279 for negative and 277 for numerator which should be correct\n",
    "        # maybe add more to the dataset because a lot of words appear only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 \n",
    "# test our data on model.csv to see if it guesses the sentences class correctly\n",
    "\n",
    "model = pd.read_csv(\"model.csv\")  # this csv file is the model is what we'll be conducting out testing phase on\n",
    "# model = model['I am confident in my abilities to achieve my goals.'].str.split() # ** uncomment this later # after changing sentences from I'm to I am I had to change the header not sure why\n",
    "model = model['I am surrounded by peace and tranquility.'].str.split() # ** uncomment this later\n",
    "# model = model['I am grateful for the opportunities in my life.'].str.split() # ** this is just for the new testing phase\n",
    "\n",
    "test_predictions = 'test_predictions.csv'  # this csv file will store the sentence along with its according group \n",
    "\n",
    "# we do need this becasue it deletes everything from the previously ran csv file, but we don't need to add headers, just open it as a write file I think.\n",
    "# i don't remember if we still need headers or not \\\\ no we don't \n",
    "with open(test_predictions, 'w') as file:  # put in a header for the predictions file\n",
    "    pass # empties the file\n",
    "    # writer = csv.writer(file)\n",
    "    # writer.writerow(headers)\n",
    "# ----------------\n",
    "\n",
    "positiveLikeliness = 1\n",
    "negativeLikeliness = 1\n",
    "\n",
    "# work on thiss ->\n",
    "for sentences in model: \n",
    "    positiveLikeliness = 1\n",
    "    negativeLikeliness = 1\n",
    "    for word in sentences:\n",
    "        # we need to pull the positive likeness\n",
    "        # since we are sorting positve and negative in 2 separate dictionaries we no longer need to store \"p\" or 'n\" in the key value \n",
    "        if word in conditionalProbabilitiesPos:\n",
    "            positiveLikeliness *= conditionalProbabilitiesPos[word] # this is the probability and we are multiplying it \n",
    "        else :\n",
    "            #  positiveLikeliness *= 0.000001   #sort of fixes the issue\n",
    "            positiveLikeliness *= p(word,positive) # smoothing\n",
    "        if word in conditionalProbabilitiesNeg:\n",
    "             negativeLikeliness *= conditionalProbabilitiesNeg[word]\n",
    "        else :                          \n",
    "            # negativeLikeliness *= 0.000001   #sort of fixes the issue\n",
    "            negativeLikeliness *= p(word,negative) # smoothing\n",
    "                                            # incorporate smoothing here instead \n",
    "                                            # else: run the p method but with the word that doesn't show up which would cause it to automatically smooth for us\n",
    "\n",
    "    # once we figured out the probability for each sentence we compare the pos and neg values and write it into the file\n",
    "    with open(test_predictions, 'a') as test_file:         \n",
    "        if positiveLikeliness > negativeLikeliness: # technically should multiply both by 1/2\n",
    "                # print('positveLikeness:',positiveLikeliness,'\\nnegativeLikeness:',negativeLikeliness,\"\\n\")\n",
    "                # print('positive\\n')\n",
    "                test_file.write(\"positive: \"+' '.join(sentences)+'\\n') \n",
    "                # positive_file.write(sentences,\"Positive\") \n",
    "        else:\n",
    "            test_file.write(\"negative: \"+' '.join(sentences)+'\\n') \n",
    "            # print('negative\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing the model on more sentences\n",
    "# # positive sentences:\n",
    "\n",
    "# positive_sentences = [\n",
    "#     \"I am grateful for the opportunities in my life.\",\n",
    "#     # \"The sun is shining brightly today.\",\n",
    "#     # \"I enjoy spending time with my loved ones.\",\n",
    "#     # \"I feel energized and ready to take on the day.\",\n",
    "#     # \"My efforts are paying off.\",\n",
    "#     # \"I have a supportive and loving family.\",\n",
    "#     # \"I am surrounded by beauty and positivity.\",\n",
    "#     # \"I am making progress towards my goals.\",\n",
    "#     # \"Each day brings new possibilities.\",\n",
    "#     # \"I am proud of myself and my accomplishments.\",\n",
    "#     # \"I radiate confidence and positivity.\",\n",
    "#     # \"I am surrounded by kind and caring people.\",\n",
    "#     # \"I am capable of overcoming any challenge.\",\n",
    "#     # \"My future is full of endless opportunities.\",\n",
    "#     # \"I am blessed with good health and well-being.\",\n",
    "#     # \"I attract abundance and success into my life.\",\n",
    "#     # \"I am filled with gratitude for all that I have.\",\n",
    "#     # \"I am becoming the best version of myself.\",\n",
    "#     # \"I am surrounded by love and happiness.\",\n",
    "#     # \"I have the power to create positive change.\",\n",
    "#     # \"I am deserving of love and respect.\",\n",
    "#     # \"I am capable of achieving my dreams.\",\n",
    "#     # \"My positivity inspires others around me.\",\n",
    "#     # \"I am in control of my own happiness.\",\n",
    "#     # \"I embrace change and see it as an opportunity for growth.\",\n",
    "#     # \"I am grateful for the simple joys in life.\",\n",
    "#     # \"I am excited about the possibilities that each day brings.\",\n",
    "#     # \"I believe in my abilities and can achieve anything.\",\n",
    "#     # \"I am surrounded by supportive friends and family.\",\n",
    "#     # \"I am resilient and can overcome any obstacle.\",\n",
    "#     # \"I am grateful for the love and kindness in my life.\",\n",
    "#     # \"I am attracting positive experiences into my life.\",\n",
    "#     # \"I am constantly learning and growing.\",\n",
    "#     # \"I am surrounded by opportunities for success.\",\n",
    "#     # \"I am confident in my skills and abilities.\",\n",
    "#     # \"I am loved and appreciated by those around me.\",\n",
    "#     # \"I am open to receiving all the good things life has to offer.\",\n",
    "#     # \"I am grateful for the lessons I learn from challenges.\",\n",
    "#     # \"I am a source of positivity and inspiration.\",\n",
    "#     # \"I am capable of making a positive impact in the world.\",\n",
    "#     # \"I am surrounded by a supportive and uplifting community.\",\n",
    "#     # \"I am filled with gratitude for the present moment.\",\n",
    "#     # \"I am worthy of all the happiness and success coming my way.\",\n",
    "#     # \"I am attracting positive energy into my life.\",\n",
    "#     # \"I am surrounded by abundance in all aspects of my life.\",\n",
    "#     # \"I am grateful for the opportunities that come my way.\",\n",
    "#     # \"I am confident in my ability to overcome any obstacle.\",\n",
    "#     # \"I am creating a life filled with joy and fulfillment.\",\n",
    "#     # \"I am surrounded by love and positivity every day.\",\n",
    "#     # \"I am worthy of love happiness and success.\",\n",
    "#     # \"I am constantly growing and evolving as a person.\",\n",
    "#     # \"I am grateful for the support and encouragement I receive.\",\n",
    "#     # \"I am capable of achieving greatness in all that I do.\",\n",
    "#     # \"I am deserving of all the good things life has to offer.\",\n",
    "#     # \"I am surrounded by positive and uplifting energy.\",\n",
    "#     # \"I am confident in my unique talents and abilities.\",\n",
    "#     # \"I am grateful for the beautiful moments life brings.\",\n",
    "#     # \"I am attracting success and prosperity into my life.\",\n",
    "#     # \"I am creating positive change in the world around me.\",\n",
    "#     # \"I am deserving of love respect and happiness.\",\n",
    "#     # \"I am surrounded by peace and tranquility.\",\n",
    "#     # \"I am confident in my ability to overcome challenges.\",\n",
    "#     # \"I am surrounded by supportive and inspiring individuals.\",\n",
    "#     # \"I am grateful for the abundance of opportunities in my life.\",\n",
    "#     # \"I am excited about the positive changes happening in my life.\",\n",
    "#     # \"I am filled with gratitude for the love and support I receive.\",\n",
    "#     # \"I am attracting positive and like-minded people into my life.\",\n",
    "#     # \"I am constantly learning and growing from every experience.\",\n",
    "#     # \"I am worthy of all the good things that come my way.\",\n",
    "#     # \"I am capable of handling whatever comes my way with grace.\",\n",
    "#     # \"I am surrounded by an abundance of love and happiness.\",\n",
    "#     # \"I am grateful for the wisdom and lessons I gain from challenges.\",\n",
    "#     # \"I am attracting opportunities that align with my passions and purpose.\",\n",
    "#     # \"I am making a positive difference in the lives of others.\",\n",
    "#     # \"I am worthy of success joy and fulfillment.\",\n",
    "#     # \"I am surrounded by positive relationships and connections.\",\n",
    "#     # \"I am grateful for the abundant blessings in my life.\",\n",
    "#     # \"I am confident in my ability to overcome obstacles and achieve my goals.\",\n",
    "#     # \"I am embracing each day with a positive mindset.\",\n",
    "#     # \"I am attracting financial abundance and prosperity.\",\n",
    "#     # \"I am surrounded by a supportive and loving community.\",\n",
    "#     # \"I am grateful for the opportunities to learn and grow.\",\n",
    "#     # \"I am creating a life of joy love and fulfillment.\",\n",
    "#     # \"I am attracting positive and inspiring people into my life.\",\n",
    "#     # \"I am constantly evolving into the best version of myself.\",\n",
    "#     # \"I am deserving of happiness success and fulfillment.\",\n",
    "#     # \"I am surrounded by positive energy and good vibes.\",\n",
    "#     # \"I am confident in my ability to handle any situation that arises.\",\n",
    "#     # \"I am grateful for the love and support of my friends and family.\",\n",
    "#     # \"I am attracting opportunities that align with my passions.\",\n",
    "#     # \"I am surrounded by beauty love and abundance.\",\n",
    "#     # \"I am capable.\",\n",
    "#     \"-----------------After this line these sentences are all negative\",\n",
    "#     \"I feel overwhelmed and exhausted.\",\n",
    "# \"The weather is miserable today.\",\n",
    "# \"I'm struggling to find meaning in my life.\",\n",
    "# \"I can't seem to catch a break.\",\n",
    "# \"My efforts seem to be in vain.\",\n",
    "# \"I have a toxic and unsupportive family.\",\n",
    "# \"I am surrounded by negativity and drama.\",\n",
    "# \"I feel stuck and stagnant.\",\n",
    "# \"Each day feels like a struggle.\",\n",
    "# \"I am disappointed in myself and my failures.\",\n",
    "# \"I can't seem to shake off this feeling of sadness.\",\n",
    "# \"I am constantly surrounded by negativity.\",\n",
    "# \"I doubt my abilities to succeed.\",\n",
    "# \"My future looks bleak and uncertain.\",\n",
    "# \"I am plagued with health issues.\",\n",
    "# \"I attract failure and disappointment into my life.\",\n",
    "# \"I am filled with bitterness and resentment.\",\n",
    "# \"I am not making any progress in life.\",\n",
    "# \"I feel like a failure in all aspects of my life.\",\n",
    "# \"I'm lacking love and happiness in my life.\",\n",
    "# \"I'm powerless and unable to change my circumstances.\",\n",
    "# \"I don't believe in my potential to achieve anything.\",\n",
    "# \"My friends and family don't support me.\",\n",
    "# \"I'm facing insurmountable obstacles.\",\n",
    "# \"I fear change and see it as a threat.\",\n",
    "# \"I'm tired of the monotonous and joyless existence.\",\n",
    "# \"I doubt my abilities and feel inadequate.\",\n",
    "# \"I am unloved and unappreciated by those around me.\",\n",
    "# \"I feel unworthy of receiving good things in life.\",\n",
    "# \"I feel like giving up on everything.\",\n",
    "# \"I'm constantly facing setbacks and failures.\",\n",
    "# \"I am surrounded by negative people who bring me down.\",\n",
    "# \"I am unable to cope with challenges and stress.\",\n",
    "# \"I don't see any opportunities for success.\",\n",
    "# \"I am filled with self-doubt and insecurities.\",\n",
    "# \"I'm not capable of making a positive impact.\",\n",
    "# \"I am alone and isolated in this world.\",\n",
    "# \"I am filled with regret for the past.\",\n",
    "# \"I am unable to break free from this negative cycle.\",\n",
    "# \"I am a source of negativity and despair.\",\n",
    "# \"I am unable to escape from my problems.\",\n",
    "# \"I'm incapable of achieving anything significant.\",\n",
    "# \"I'm stuck in a hopeless and joyless life.\",\n",
    "# \"I'm constantly making mistakes and failing.\",\n",
    "# \"I am attracting negative energy into my life.\",\n",
    "# \"I am surrounded by scarcity and lack.\",\n",
    "# \"I am resentful of the opportunities that others have.\",\n",
    "# \"I'm trapped in a life full of misery.\",\n",
    "# \"I am uncertain about the future and what it holds.\",\n",
    "# \"I don't believe in myself and my abilities.\",\n",
    "# \"I am unworthy of the support and encouragement of others.\",\n",
    "# \"I am incapable of achieving greatness.\",\n",
    "# \"I am undeserving of good things in life.\",\n",
    "# \"I am surrounded by negative and toxic relationships.\",\n",
    "# \"I am filled with regret and disappointment.\",\n",
    "# \"I'm attracting failure and misfortune.\",\n",
    "# \"I am creating a negative impact in the world around me.\",\n",
    "# \"I don't believe I'll ever find happiness.\",\n",
    "# \"I am surrounded by unsupportive and uninspiring individuals.\",\n",
    "# \"I am ungrateful for the little blessings in my life.\",\n",
    "# \"I am repelling positive and like-minded people.\",\n",
    "# \"I'm stuck in a never-ending loop of negativity.\",\n",
    "# \"I'm destined to face constant hardships.\",\n",
    "# \"I'm incapable of handling challenges with grace.\",\n",
    "# \"I am surrounded by a lack of love and happiness.\",\n",
    "# \"I'm haunted by the mistakes and failures of the past.\",\n",
    "# \"I'm attracting opportunities that don't align with my passions.\",\n",
    "# \"I am not making any positive difference in the lives of others.\",\n",
    "# \"I am surrounded by negative relationships and connections.\",\n",
    "# \"I am burdened by the challenges and struggles in my life.\",\n",
    "# \"I'm attracting financial scarcity and struggles.\",\n",
    "# \"I am surrounded by a judgmental and uncaring community.\",\n",
    "# \"I am ungrateful for the lessons and growth from challenges.\",\n",
    "# \"I am creating a life of misery and despair.\",\n",
    "# \"I'm attracting negative and uninspiring people into my life.\",\n",
    "# \"I'm constantly devolving into a worse version of myself.\",\n",
    "# \"I am surrounded by negative energy and bad vibes.\",\n",
    "# \"I am incapable of handling difficult situations.\",\n",
    "# \"I am unappreciative of the love and support I receive.\",\n",
    "# \"I'm attracting opportunities that are not aligned with my goals.\",\n",
    "# \"I am incapable of finding success or happiness.\",\n",
    "# \"I'm overwhelmed with negativity in my life.\",\n",
    "# \"I am repelling financial abundance and prosperity.\",\n",
    "# \"I am surrounded by a cold and unloving community.\",\n",
    "# \"I am ungrateful for the opportunities to learn and grow.\",\n",
    "# \"I'm attracting negative and uninspired people into my life.\",\n",
    "# \"I'm constantly regressing in my personal growth.\",\n",
    "# \"I am surrounded by negative relationships and toxic connections.\",\n",
    "# \"I am burdened by the challenges and struggles in my life.\",\n",
    "# \"I'm attracting financial scarcity and endless struggles.\",\n",
    "# \"I am surrounded by a judgmental and unsupportive community.\",\n",
    "# \"I am ungrateful for the lessons and growth from challenges.\",\n",
    "# \"I am creating a life of misery and despair.\",\n",
    "# \"I'm attracting negative and uninspiring people into my life.\",\n",
    "# \"I'm constantly devolving into a worse version of myself.\",\n",
    "# \"I am surrounded by negative energy and bad vibes.\",\n",
    "# \"I am incapable of handling difficult situations.\",\n",
    "# \"I am unappreciative of the love and support I receive.\",\n",
    "# \"I'm attracting opportunities that are not aligned with my goals.\",\n",
    "# \"I am incapable of finding success or happiness.\",\n",
    "# \"I'm overwhelmed with negativity in my life.\",\n",
    "# \"I am repelling financial abundance and prosperity.\",\n",
    "# \"I am surrounded by a cold and unloving community.\",\n",
    "# \"I am ungrateful for the opportunities to learn and grow.\",\n",
    "# \"I'm attracting negative and uninspired people into my life.\",\n",
    "# \"I'm constantly regressing in my personal growth.\",\n",
    "# ]\n",
    "\n",
    "\n",
    "# model_set_file = open(model_set_text, 'w') # open the file in write mode to add positive sentences\n",
    "# with open(model_set_text, 'w') as model_set_file:\n",
    "#     for sentences in positive_sentences: # positive_sentences is just the list of sentences above this chunk of code\n",
    "#         model_set_file.write(f'{sentences}\\n') # write as a formatted string \n",
    "\n",
    "\n",
    "# # can delete all of this under\n",
    "# # positive_file = open(positive_text, 'w') # open the file in write mode to add positive sentences\n",
    "# # with open(negative_text, 'w') as negative_file:\n",
    "# #     for sentences in positive_sentences:\n",
    "# #         positive_file.write(f'{sentences}\\n') # write as a formatted string \n",
    "\n",
    "\n",
    "# # truncator(positive_text, positive_file, model_set_text, model_set_file, 80, False) # these are just names for reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont really need to do this, can delete \n",
    "\n",
    "# rewriting thought process; can delete later: make it so that the user generated 2 files, whom are part of 2 groups. The naive base classifier will go through both files taking words\n",
    "# and learning from them, once that is done the user can generate more words that the model will try to place into a group or.. the user can play around with it by\n",
    "# entering their own sentences and the computer will tell them the group that belongs to\n",
    "\n",
    "# - what we should do\n",
    "# keep positive and negative and reqwrite everything else \n",
    "\n",
    "# # trying to figure out how to get 20% of the lines\n",
    "\n",
    "\n",
    "\n",
    "# def splitFileTwentyPercent(input_file):\n",
    "#     input_file = pd.read_csv(input_file)  \n",
    "#     # fileWithRemovedLines = input_file[:-10] # instead of manually inputting 20% of the lines( 10 lines), lets remove 20% of the lines\n",
    "#     fileWithRemovedLines = (input_file[:int(len(input_file)*20*0.01)]) \n",
    "#     return fileWithRemovedLines\n",
    "\n",
    "\n",
    "#     #     def removeLastTenLines(input_file):\n",
    "#     # input_file = pd.read_csv(input_file)  \n",
    "#     # fileWithRemovedLines = input_file[:-10] # instead of manually inputting 20% of the lines( 10 lines), lets remove 20% of the lines\n",
    "#     # # fileWithRemovedLines = (input_file[:int(len(input_file)*20*0.01)]) \n",
    "#     # return fileWithRemovedLines\n",
    "\n",
    "# # 20% of the lines\n",
    "\n",
    "\n",
    "    \n",
    "# positive_training = splitFileTwentyPercent('positive.csv') # this is now 80% of the training set \n",
    "\n",
    "\n",
    "# print(positive_training)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Making it user interactive \n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing if it puts it into a list [\"Hello! How are you? I hope you're doing well\", ' Have a great day!']\n",
      "group one: []\n",
      "group two: []\n"
     ]
    }
   ],
   "source": [
    "# current work in progress\n",
    "# done but revised, dont use\n",
    "\n",
    "# snake case is convential in python and uses lowercase letters along with underscores \n",
    "\n",
    "# user generates sentences\n",
    "# create a method that automatically creates a list of sentences\n",
    "# this should work for any number of groups\n",
    "\n",
    "# later we'll have to compare which word has the greatest value\n",
    "\n",
    "# maybe instead create an input where the user adds hundreds of sentences and then the method splits those sentences into a list. then trains the model\n",
    "# this way the user can get sentences off of random websites and categorize them. So they could get the sentences from chatgpt, a book, a website, etc.\n",
    "# def groupBuilder(sentences):\n",
    "    \n",
    "\n",
    "groupOne = [  # make an array of sentences\n",
    "    # \"sentence1\",\n",
    "    # \"sentence2\",\n",
    "]\n",
    "\n",
    "groupTwo = [ \n",
    "    # \"sentence1\",\n",
    "    # \"sentence2\",\n",
    "]\n",
    "\n",
    "\n",
    "# ** realizing we dont need sentences_to_list because .split already places the words into a list\n",
    "\n",
    "\n",
    "def split_sentences(sentences):\n",
    "    return sentences.split(\".\")  # when the sentence gets added to the list so does the space after the period\n",
    "    # split the sentences by periods\n",
    "    \n",
    "    # might have to add an edge case here to get rid of an empty string after the last period\n",
    "    \n",
    "\n",
    "def sentences_to_list(list_of_sentences, group): # put the sentences in to a list # list of lists\n",
    "    for sentence in list_of_sentences:\n",
    "        group.append(sentence)\n",
    "    group.pop() # theres an extra empty string after the last period, meaning user must put a period after the last sentence\n",
    "\n",
    "\n",
    "\n",
    "def something():\n",
    "    sentences = input(\"Train me by giving me sentences. Remember the more sentences, the more accurate I will be.\")\n",
    "    # while sentence != 'done': # i think this was if you wanted to enter sentence by sentence; meaning i dont think we need this anymore\n",
    "    sentences = split_sentences(sentences)\n",
    "    sentences_to_list(sentences, groupOne) # put it in the list and then we pass it through the functions we created earlier \n",
    "\n",
    "    # separate group 1 and group 2\n",
    "\n",
    "    sentences = input(\"Train me by giving me sentences. Remember the more sentences, the more accurate I will be.\")\n",
    "    sentences = split_sentences(sentences)\n",
    "    sentences_to_list(sentences, groupTwo) # this will only work for 2 groups, possibly update in the future to accomodate n groups\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Test the method\n",
    "input_text = \"Hello! How are you? I hope you're doing well. Have a great day!\"\n",
    "print(\"testing if it puts it into a list\",split_sentences(input_text))\n",
    "# sentences_list = split_sentences(input_text)\n",
    "# print(sentences_list)\n",
    "#\n",
    "something()\n",
    "#this is sentence 1. sentence 2 is here. third sentence is here. 4th sentence.\n",
    "# this is the second group sentence 1. this is the second group with sentence 2.\n",
    "    \n",
    "print(\"group one:\",groupOne)\n",
    "print('group two:',groupTwo)\n",
    "\n",
    "# testing each method below\n",
    "# list_of_sentences = (split_sentences('hello. how are you. this is sentence 3. sentence 4.')) \n",
    "# print(sentences_to_list(list_of_sentences))\n",
    "\n",
    "#The quick brown fox jumps over the lazy dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Groups\n",
      "[['Happy', 'Joy', 'laughter', 'love', 'sunshine', 'serenity', 'contentment', 'delight', 'bliss', 'exuberance', 'jubilation', 'euphoria', 'enchantment', 'laughter', 'harmony', 'gratitude', 'peace', 'serendipity', 'kindness', 'compassion', 'friendship', 'family', 'togetherness', 'unity', 'hope', 'optimism', 'giggles', 'elation', 'sparkle', 'cuddles', 'warmth', 'beauty', 'radiant', 'excitement', 'carefree', 'wonder', 'playfulness', 'gratitude', 'amazement', 'serenity', 'harmony', 'comfort', 'music', 'affection', 'sharing', 'giving', 'blossoming', 'joyous', 'carefree', 'lighthearted', 'zest', 'heartwarming', 'sunshine', 'daisies', 'tranquility', 'cozy', 'uplifting', 'kindness', 'sparkling', 'heartwarming', 'inspiration', 'serenity', 'cuddles', 'precious', 'cherished', 'love', 'laughter', 'blessings', 'contentment', 'happiness', 'blissful', 'celebration', 'vibrant', 'delightful', 'magical', 'wonderment', 'harmony', 'unity', 'love', 'peace', 'laughter', 'gratitude', 'serenity', 'radiant', 'jubilation', 'compassion', 'contentment', 'kindness', 'harmony', 'togetherness', 'warmth', 'delight', 'grace', 'fulfillment', 'elation', 'serenity', 'joyfulness', 'laughter', 'harmony', 'bliss', 'affection', 'optimism', 'compassion', 'joyous', 'jubilant', 'happiness', 'cheer', 'playfulness', 'radiant', 'cherished', 'serene', 'vibrant', 'delight', 'contentment', 'euphoria', 'warmth', 'gratitude', 'togetherness', 'laughter', 'comfort', 'harmony', 'jubilation', 'love', 'sunshine', 'joyfulness', 'serenity', 'elation', 'kindness', 'bliss', 'radiant', 'affection', 'happiness', 'harmony', 'compassion', 'gratitude', 'laughter', 'delight', 'playfulness', 'kindness', 'togetherness', 'love', 'serenity', 'joy', 'comfort', 'radiance', 'blessings', 'fulfillment', 'jubilation', 'compassion', 'hope', 'warmth', 'contentment', 'harmony', 'joyfulness', 'delight', 'love', 'happiness', 'kindness', 'laughter', 'serenity', 'togetherness', 'gratitude', 'radiant', 'compassion', 'euphoria', 'peace', 'harmony', 'elation', 'playfulness', 'bliss', 'serenity', 'joy', 'love', 'comfort', 'gratitude', 'laughter', 'harmony', 'togetherness', 'happiness', 'warmth', 'playfulness', 'affection', 'contentment', 'radiant', 'serenity', 'joyfulness', 'compassion', 'bliss', 'kindness', 'delight', 'euphoria', 'harmony', 'gratitude', 'jubilation', 'laughter', 'love', 'fulfillment', 'togetherness', 'radiant', 'contentment', 'harmony', 'joyfulness', 'affection', 'serenity', 'happiness', 'compassion', 'delight', 'kindness', 'gratitude', 'jubilation', 'laughter', 'playfulness', 'euphoria', 'warmth', 'love', 'togetherness', 'harmony', 'bliss', 'radiant', 'joyfulness', 'contentment', 'compassion', 'serenity', 'kindness', 'happiness', 'delight', 'laughter', 'gratitude', 'playfulness', 'harmony', 'euphoria', 'affection', 'jubilation', 'warmth', 'compassion', 'love', 'serenity', 'joy', 'kindness', 'laughter', 'contentment', 'togetherness', 'gratitude', 'harmony', 'euphoria', 'playfulness', 'bliss', 'affection', 'radiant', 'happiness', 'compassion', 'jubilation', 'warmth', 'delight', 'harmony', 'laughter', 'serenity', 'kindness', 'togetherness', 'gratitude', 'playfulness', 'euphoria', 'love', 'compassion', 'joy', 'happiness', 'bliss', 'radiant', 'contentment', 'harmony', 'laughter', 'kindness', 'serenity', 'togetherness', 'gratitude', 'euphoria', 'affection', 'jubilation', 'warmth', 'delight', 'compassion', 'playfulness', 'love', 'joyfulness', 'bliss', 'harmony', 'happiness', 'serenity', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'contentment', 'playfulness', 'radiant', 'compassion', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity', 'happiness', 'kindness', 'laughter', 'togetherness', 'gratitude', 'affection', 'bliss', 'contentment', 'compassion', 'playfulness', 'radiant', 'jubilation', 'warmth', 'delight', 'euphoria', 'love', 'harmony', 'joy', 'serenity'], ['sad', 'Grief', 'sorrow', 'despair', 'loneliness', 'heartache', 'anguish', 'melancholy', 'misery', 'depression', 'pain', 'suffering', 'loss', 'tragedy', 'tearful', 'mourning', 'weeping', 'somber', 'desolation', 'forlorn', 'brokenhearted', 'dismal', 'wretched', 'despondency', 'heartbreak', 'regret', 'isolation', 'bleak', 'downcast', 'somber', 'disheartened', 'glum', 'woeful', 'dejected', 'mournful', 'dreary', 'unhappy', 'sorrowful', 'downhearted', 'tearyeyed', 'disconsolate', 'hopeless', 'devastated', 'blue', 'bereaved', 'morose', 'melancholic', 'desolate', 'somberness', 'mourn', 'sorrowing', 'griefstricken', 'inconsolable', 'crestfallen', 'pained', 'tormented', 'heavyhearted', 'dark', 'despondent', 'lowspirited', 'rueful', 'hurt', 'down', 'anguished', 'woebegone', 'gloomy', 'broken', 'tormented', 'dismal', 'hurting', 'sorrowfilled', 'heartrending', 'regretful', 'downhearted', 'cheerless', 'heartrending', 'lament', 'suffering', 'traumatic', 'heartwrenching', 'bitter', 'dreariness', 'lamentable', 'weep', 'aching', 'sobbing', 'pitiful', 'soulcrushing', 'aching', 'disheartenment', 'somber', 'bleakness', 'anguishing', 'depressive', 'bereft', 'hurting', 'tearjerking', 'painful', 'sorrowed', 'mournfully', 'melancholia', 'tragedy', 'adversity', 'darkness', 'tears', 'loneliness', 'melancholy', 'griefstricken', 'sorrowful', 'mourn', 'desolation', 'dispirited', 'lamenting', 'emotional', 'heartrending', 'griefstricken', 'sorrowful', 'despair', 'loneliness', 'heartache', 'anguish', 'melancholy', 'misery', 'depression', 'pain', 'suffering', 'loss', 'tragedy', 'tearful', 'mourning', 'weeping', 'somber', 'desolation', 'forlorn', 'brokenhearted', 'dismal', 'wretched', 'despondency', 'heartbreak', 'regret', 'isolation', 'bleak', 'downcast', 'somber', 'disheartened', 'glum', 'woeful', 'dejected', 'mournful', 'dreary', 'unhappy', 'sorrowful', 'downhearted', 'tearyeyed', 'disconsolate', 'hopeless', 'devastated', 'blue', 'bereaved', 'morose', 'melancholic', 'desolate', 'somberness', 'mourn', 'sorrowing', 'griefstricken', 'inconsolable', 'crestfallen', 'pained', 'tormented', 'heavyhearted', 'dark', 'despondent', 'lowspirited', 'rueful', 'hurt', 'down', 'anguished', 'woebegone', 'gloomy', 'broken', 'tormented', 'dismal', 'hurting', 'sorrowfilled', 'heartrending', 'regretful', 'downhearted', 'cheerless', 'heartrending', 'lament', 'suffering', 'traumatic', 'heartwrenching', 'bitter', 'dreariness', 'lamentable', 'weep', 'aching', 'sobbing', 'pitiful', 'soulcrushing', 'aching', 'disheartenment', 'somber', 'bleakness', 'anguishing', 'depressive', 'bereft', 'hurting', 'tearjerking', 'painful', 'sorrowed', 'mournfully', 'melancholia', 'tragedy', 'adversity', 'darkness', 'tears', 'loneliness', 'melancholy', 'griefstricken', 'sorrowful', 'mourn', 'desolation', 'dispirited', 'lamenting', 'emotional', 'heartrending', 'griefstricken', 'sorrowful', 'torment', 'brokenness', 'heavyhearted', 'mournful', 'agony', 'pain', 'sorrowful', 'suffering', 'wistful', 'lonely', 'disconsolate', 'despair', 'grief', 'mourn', 'misery', 'heartache', 'sorrowful', 'mournful', 'anguish', 'tearful', 'melancholic', 'unhappy', 'sad', 'sorrow', 'dejected', 'downhearted', 'brokenhearted', 'somber', 'tragic', 'bleak', 'downcast', 'desolate', 'disheartened', 'glum', 'woeful', 'blue', 'morose', 'pained', 'tormented', 'dark', 'lowspirited', 'rueful', 'hurt', 'anguished', 'woebegone', 'gloomy', 'broken', 'tormented', 'dismal', 'hurting', 'sorrowfilled', 'regretful', 'cheerless', 'bitter', 'painful', 'mournfully', 'tragedy', 'adversity', 'tears', 'griefstricken', 'sorrowful', 'mourn', 'desolation', 'lamenting', 'emotional', 'sorrowful', 'torment', 'brokenness', 'heavyhearted', 'mournful', 'agony', 'pain', 'sorrowful', 'suffering', 'wistful', 'lonely', 'disconsolate', 'despair', 'grief', 'mourn', 'misery', 'heartache', 'sorrowful', 'mournful', 'anguish', 'tearful', 'melancholic', 'unhappy', 'sad', 'sorrow', 'dejected', 'downhearted', 'brokenhearted', 'somber', 'tragic', 'bleak', 'downcast', 'desolate', 'disheartened', 'glum', 'woeful', 'blue', 'morose', 'pained', 'tormented', 'dark', 'lowspirited', 'rueful', 'hurt', 'anguished', 'woebegone', 'gloomy', 'broken', 'tormented', 'dismal', 'hurting', 'sorrowfilled', 'regretful', 'cheerless', 'bitter', 'painful', 'mournfully', 'tragedy', 'adversity', 'tears', 'griefstricken', 'sorrowful', 'mourn', 'desolation', 'lamenting', 'emotional', 'mournful', 'lamenting', 'heartbroken', 'mournful', 'grieving', 'sorrowful', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping', 'aching', 'tearstained', 'lamenting', 'despairing', 'grieving', 'sorrowful', 'heartbroken', 'mournful', 'weeping'], ['fear', 'Terror', 'fear', 'dread', 'anxiety', 'fright', 'panic', 'horror', 'phobia', 'alarm', 'trepidation', 'nightmare', 'apprehension', 'unease', 'spinechilling', 'terrorstricken', 'petrified', 'chilling', 'terrifying', 'spooky', 'daunting', 'hairraising', 'shudder', 'shiver', 'petrifying', 'creepy', 'fearful', 'ominous', 'spinetingling', 'ghastly', 'panicstricken', 'alarming', 'eerie', 'anxious', 'shivering', 'quivering', 'startle', 'shock', 'panic', 'attack', 'horrified', 'unsettling', 'fearinducing', 'panic', 'disorder', 'frightful', 'cold', 'sweat', 'bloodcurdling', 'petrifying', 'jittery', 'jumpy', 'unnerving', 'nervousness', 'distress', 'uneasiness', 'agitation', 'disquiet', 'concern', 'panic', 'fearfulness', 'consternation', 'horror', 'terror', 'apprehension', 'alarm', 'terror', 'fear', 'dread', 'anxiety', 'fright', 'panic', 'horror', 'phobia', 'alarm', 'trepidation', 'nightmare', 'apprehension', 'unease', 'spinechilling', 'terrorstricken', 'petrified', 'chilling', 'terrifying', 'spooky', 'daunting', 'hairraising', 'shudder', 'shiver', 'petrifying', 'creepy', 'fearful', 'ominous', 'spinetingling', 'ghastly', 'panicstricken', 'alarming', 'eerie', 'anxious', 'shivering', 'quivering', 'startle', 'shock', 'panic', 'attack', 'horrified', 'unsettling', 'fearinducing', 'panic', 'disorder', 'frightful', 'cold', 'sweat', 'bloodcurdling', 'petrifying', 'jittery', 'jumpy', 'unnerving', 'nervousness', 'distress', 'uneasiness', 'agitation', 'disquiet', 'concern', 'panic', 'fearfulness', 'consternation', 'horror', 'terror', 'apprehension', 'alarm', 'fear', 'dread', 'anxiety', 'fright', 'panic', 'horror', 'phobia', 'alarm', 'trepidation', 'nightmare', 'apprehension', 'unease', 'spinechilling', 'terrorstricken', 'petrified', 'chilling', 'terrifying', 'spooky', 'daunting', 'hairraising', 'shudder', 'shiver', 'petrifying', 'creepy', 'fearful', 'ominous', 'spinetingling', 'ghastly', 'panicstricken', 'alarming', 'eerie', 'anxious', 'shivering', 'quivering', 'startle', 'shock', 'panic', 'attack', 'horrified', 'unsettling', 'fearinducing', 'panic', 'disorder', 'frightful', 'cold', 'sweat', 'bloodcurdling', 'petrifying', 'jittery', 'jumpy', 'unnerving', 'nervousness', 'distress', 'uneasiness', 'agitation', 'disquiet', 'concern', 'panic', 'fearfulness', 'consternation', 'horror', 'terror', 'apprehension', 'alarm', 'terror', 'fear', 'dread', 'anxiety', 'fright', 'panic', 'horror', 'phobia', 'alarm', 'trepidation', 'nightmare', 'apprehension', 'unease', 'spinechilling', 'terrorstricken', 'petrified', 'chilling', 'terrifying', 'spooky', 'daunting', 'hairraising', 'shudder', 'shiver', 'petrifying', 'creepy', 'fearful', 'ominous', 'spinetingling', 'ghastly', 'panicstricken', 'alarming', 'eerie', 'anxious', 'shivering', 'quivering', 'startle', 'shock', 'panic', 'attack', 'horrified', 'unsettling', 'fearinducing', 'panic', 'disorder', 'frightful', 'cold', 'sweat', 'bloodcurdling', 'petrifying', 'jittery', 'jumpy', 'unnerving', 'nervousness', 'distress', 'uneasiness', 'agitation', 'disquiet', 'concern', 'panic', 'fearfulness', 'consternation', 'horror', 'terror', 'apprehension', 'alarm', 'terror', 'fear', 'dread', 'anxiety', 'fright', 'panic', 'horror', 'phobia', 'alarm', 'trepidation', 'nightmare', 'apprehension', 'unease', 'spinechilling', 'terrorstricken', 'petrified', 'chilling', 'terrifying', 'spooky', 'daunting', 'hairraising', 'shudder', 'shiver', 'petrifying', 'creepy', 'fearful', 'ominous', 'spinetingling', 'ghastly', 'panicstricken', 'alarming', 'eerie', 'anxious', 'shivering', 'quivering', 'startle', 'shock', 'panic', 'attack', 'horrified', 'unsettling', 'fearinducing', 'panic', 'disorder', 'frightful', 'cold', 'sweat', 'bloodcurdling', 'petrifying', 'jittery', 'jumpy', 'unnerving', 'nervousness', 'distress', 'uneasiness', 'agitation', 'disquiet', 'concern', 'panic', 'fearfulness', 'consternation', 'horror', 'terror', 'apprehension', 'alarm', 'fear', 'dread', 'anxiety', 'fright', 'panic', 'horror', 'phobia', 'alarm', 'trepidation', 'nightmare', 'apprehension', 'unease', 'spinechilling', 'terrorstricken', 'petrified', 'chilling', 'terrifying', 'spooky', 'daunting', 'hairraising', 'shudder', 'shiver', 'petrifying', 'creepy', 'fearful', 'ominous', 'spinetingling', 'ghastly', 'panicstricken', 'alarming', 'eerie', 'anxious', 'shivering', 'quivering', 'startle', 'shock', 'panic', 'attack', 'horrified', 'unsettling', 'fearinducing', 'panic', 'disorder', 'frightful', 'cold', 'sweat', 'bloodcurdling', 'petrifying', 'jittery', 'jumpy', 'unnerving', 'nervousness', 'distress', 'uneasiness', 'agitation', 'disquiet', 'concern', 'panic', 'fearfulness', 'consternation', 'horror', 'terror', 'apprehension', 'alarm', 'terror', 'fear', 'dread', 'anxiety', 'fright', 'panic', 'horror', 'phobia', 'alarm', 'trepidation', 'nightmare', 'apprehension', 'unease', 'spinechilling', 'terrorstricken', 'petrified', 'chilling', 'terrifying', 'spooky', 'daunting', 'hairraising', 'shudder', 'shiver', 'petrifying', 'creepy', 'fearful', 'ominous', 'spinetingling', 'ghastly', 'panicstricken', 'alarming', 'eerie', 'anxious', 'shivering', 'quivering', 'startle', 'shock', 'panic', 'attack', 'horrified', 'unsettling', 'fearinducing', 'panic', 'disorder', 'frightful', 'cold', 'sweat', 'bloodcurdling', 'petrifying', 'jittery', 'jumpy', 'unnerving', 'nervousness', 'distress', 'uneasiness', 'agitation', 'disquiet', 'concern', 'panic', 'fearfulness', 'consternation', 'horror', 'terror', 'apprehension', 'alarm', 'terror', 'fear', 'dread', 'anxiety', 'fright', 'panic', 'horror', 'phobia', 'alarm', 'trepidation', 'nightmare', 'apprehension', 'unease', 'spinechilling', 'terrorstricken', 'petrified', 'chilling', 'terrifying', 'spooky', 'daunting', 'hairraising', 'shudder', 'shiver', 'petrifying', 'creepy', 'fearful', 'ominous', 'spinetingling', 'ghastly', 'panicstricken', 'alarming', 'eerie', 'anxious', 'shivering', 'quivering', 'startle', 'shock', 'panic', 'attack', 'horrified', 'unsettling', 'fearinducing', 'panic', 'disorder', 'frightful', 'cold', 'sweat', 'bloodcurdling', 'petrifying', 'jittery', 'jumpy', 'unnerving', 'nervousness', 'distress', 'uneasiness', 'agitation', 'disquiet', 'concern', 'panic', 'fearfulness', 'consternation', 'horror', 'terror', 'apprehension', 'alarm', 'terror', 'fear', 'dread', 'anxiety', 'fright', 'panic', 'horror', 'phobia', 'alarm', 'trepidation', 'nightmare', 'apprehension', 'unease', 'spinechilling', 'terrorstricken', 'petrified', 'chilling', 'terrifying', 'spooky', 'daunting', 'hairraising', 'shudder', 'shiver', 'petrifying', 'creepy', 'fearful', 'ominous', 'spinetingling', 'ghastly', 'panicstricken', 'alarming', 'eerie', 'anxious', 'shivering', 'quivering', 'startle', 'shock', 'panic', 'attack', 'horrified', 'unsettling', 'fearinducing', 'panic', 'disorder', 'frightful', 'cold', 'sweat', 'bloodcurdling', 'petrifying', 'jittery', 'jumpy', 'unnerving', 'nervousness', 'distress', 'uneasiness', 'agitation', 'disquiet', 'concern', 'panic', 'fearfulness', 'consternation']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n-\\nP(w|c) = (c(w,c)+k) / count(c) + |v|\\nw = the word, c = positive or negative sentence group, c on denominator is the number of words in total (in that group and not unique) , |v| is the number of unique words we have in total\\n\\nwe split the words into single words. our other method used csv files and took the sentences and then words in each sentence each giving them a score. \\nhow important is it that we store the sentences into csv files because I think we don't need the csv file to do it.\\nIt would technically be easier to count the total number of words among other things because they would all be stored in a list, the only downside \\nis that we already have the code for a csv file and if we don't use a csv file we'll have to change a significant amount of the code.\\nOption one is more viable\\noption two is cleaner and more userfriendly but more time consuming \\n\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note: cell above works, this is a revamp of that cell \n",
    "\n",
    "# since this works, the next step is to take input fromm the user asking them how many groups they want and then \n",
    "# ill have another function that makes the groups with a for loop and then populates it\n",
    "\n",
    "import string\n",
    "#revision\n",
    "\n",
    "encapsulated_groups = [] # now all the lists are in here, however, I don't know how to assign the group to what the user writes. do i just say \"your sentence belongs in group 1\" but group 1\n",
    "                        # doesn't mean anything to the user, maybe I should ask the user to make the first sentence the title, but i'll implement this later. \n",
    "                        # for now i'll pretend we already implemented this and that that first sentence is the title for the group\n",
    "                        # i think i have to turn these into csv files anyways\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_sentences(sentences, group):\n",
    "    group = []\n",
    "    # clean the sentences\n",
    "   \n",
    "    # Create a translation table to remove punctuation\n",
    "    # translation_table = str.maketrans('', '', string.punctuation)\n",
    "    # words_without_punctuation = text.translate(translation_table).split()\n",
    "\n",
    "    # str.maketrans('characters_to_replace', 'replacement_characters', 'characters_to_remove')\n",
    "    translation_table = str.maketrans('','', string.punctuation) \n",
    "    group = sentences.translate(translation_table).split()\n",
    "\n",
    "    # group = sentences.replace('.','').split()#(\".\")  # when the sentence gets added to the list so does the space after the period\n",
    "    # group = group.split()\n",
    "    # group.pop() \n",
    "    encapsulated_groups.append(group)\n",
    "    # return group\n",
    "\n",
    "# this works b/c we just need the words, we don't care about sentences\n",
    "\n",
    "def something(): # rename this\n",
    "\n",
    "    # number of groups\n",
    "    error = True # an error is if the user enters something that is:    not an int   or   groups < 2   or  groups > 50\n",
    "    while error == True:\n",
    "        num_of_sentence_groups = input(\"Enter the number of number groups you would like\")\n",
    "        error = False\n",
    "        try: \n",
    "            num_of_sentence_groups = int(num_of_sentence_groups) \n",
    "            if num_of_sentence_groups < 2 or num_of_sentence_groups > 50: # change to 2 later \n",
    "                print(\"Please enter a number greater than 2 or less than 50\")\n",
    "                error = True\n",
    "        except ValueError:\n",
    "            num_of_sentence_groups = print(\"Please enter a valid number\")\n",
    "            error = True\n",
    "    print(num_of_sentence_groups,\"Groups\")\n",
    "\n",
    "# havent tested anything below this yet \n",
    "\n",
    "    sentence_groups_created = 0\n",
    "    while sentence_groups_created < num_of_sentence_groups:  # create new sentence groups until the number of total sentence groups have been satisified\n",
    "        sentences = input(\"Train me by giving me sentences. Remember the more sentences, the more accurate I will be.\")\n",
    "        split_sentences(sentences, f\"group{sentence_groups_created}\") # i dont think the f'group{} is doing anything, can probably get rid of the parameter in the method too\n",
    "        # sentences_to_list(sentences, groupOne) # how to make a new group # can i make a new list named \"group(counte)\"\n",
    "        # sentences_to_list(sentences,f\"group{sentence_groups_created}\")\n",
    "        sentence_groups_created += 1\n",
    "\n",
    "    \n",
    "\n",
    "    # sentences = input(\"Train me by giving me sentences. Remember the more sentences, the more accurate I will be.\")\n",
    "    # # while sentence != 'done': # i think this was if you wanted to enter sentence by sentence; meaning i dont think we need this anymore\n",
    "    # sentences = split_sentences(sentences)\n",
    "    # sentences_to_list(sentences, groupOne) # put it in the list and then we pass it through the functions we created earlier \n",
    "\n",
    "    # # separate group 1 and group 2\n",
    "\n",
    "    # sentences = input(\"Train me by giving me sentences. Remember the more sentences, the more accurate I will be.\")\n",
    "    # sentences = split_sentences(sentences)\n",
    "    # sentences_to_list(sentences, groupTwo) # this will only work for 2 groups, possibly update in the future to accomodate n groups\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Test the method\n",
    "# input_text = \"Hello! How are you? I hope you're doing well. Have a great day!\"\n",
    "# print(\"testing if it puts it into a list\",split_sentences(input_text))\n",
    "# sentences_list = split_sentences(input_text)\n",
    "# print(sentences_list)\n",
    "#\n",
    "something()\n",
    "#this is sentence 1. sentence 2 is here. third sentence is here. 4th sentence.\n",
    "# this is the second group sentence 1. this is the second group with sentence 2.\n",
    "    \n",
    "print(encapsulated_groups)\n",
    "\n",
    "# brainstorming:\n",
    "'''\n",
    "-\n",
    "P(w|c) = (c(w,c)+k) / count(c) + |v|\n",
    "w = the word, c = positive or negative sentence group, c on denominator is the number of words in total (in that group and not unique) , |v| is the number of unique words we have in total\n",
    "\n",
    "we split the words into single words. our other method used csv files and took the sentences and then words in each sentence each giving them a score. \n",
    "how important is it that we store the sentences into csv files because I think we don't need the csv file to do it.\n",
    "It would technically be easier to count the total number of words among other things because they would all be stored in a list, the only downside \n",
    "is that we already have the code for a csv file and if we don't use a csv file we'll have to change a significant amount of the code.\n",
    "Option one is more viable\n",
    "option two is cleaner and more userfriendly but more time consuming \n",
    "'''\n",
    "# Positive I am very happy today because it is sunny\n",
    "# Negative super sad since theres a lot of cold and rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "this\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'likeliness' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(encapsulated_groups)):\n\u001b[1;32m      9\u001b[0m     \u001b[39mfor\u001b[39;00m words \u001b[39min\u001b[39;00m encapsulated_groups[i]:  \n\u001b[0;32m---> 10\u001b[0m         likeliness \n\u001b[1;32m     11\u001b[0m         \u001b[39m# first statment checks if words exists in the dictionary, this prevents a key error. second statement checks if it does exist then does the word match to the corresponding group or is the word from another group \u001b[39;00m\n\u001b[1;32m     12\u001b[0m         \u001b[39mif\u001b[39;00m words \u001b[39min\u001b[39;00m conditionalProbabilitiesWithGroup :\n",
      "\u001b[0;31mNameError\u001b[0m: name 'likeliness' is not defined"
     ]
    }
   ],
   "source": [
    "# i dont think i need this anymore\n",
    "\n",
    "\n",
    "# all the group names\n",
    "# todo \n",
    "for i in range(len(encapsulated_groups)):\n",
    "    print(encapsulated_groups[i][0])\n",
    "\n",
    "conditionalProbabilitiesWithGroup = {'key': [1, 'group name']}\n",
    "\n",
    "for i in range(len(encapsulated_groups)):\n",
    "    for words in encapsulated_groups[i]:  \n",
    "        likeliness \n",
    "        # first statment checks if words exists in the dictionary, this prevents a key error. second statement checks if it does exist then does the word match to the corresponding group or is the word from another group \n",
    "        if words in conditionalProbabilitiesWithGroup :\n",
    "            if conditionalProbabilitiesWithGroup [words][1] == encapsulated_groups[i][0]: # for some reason i cant put it in the same line with an '&'\n",
    "                pass\n",
    "        else:\n",
    "            # print('run the p function','words not existent')\n",
    "            # doing top first\n",
    "            likeliness = p(words, encapsulated_groups[i][0])  # the word and the group name\n",
    "            conditionalProbabilitiesWithGroup.update({words : likeliness}) # class P for positive  #**** might need to reset the dictionary each time for each sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group name\n",
      "{'key': [1, 'group name']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print('happy' not in conditionalProbabilitiesPosWithGroup)\n",
    "# for i in range(len(encapsulated_groups)):\n",
    "#     for words in encapsulated_groups[i]:  \n",
    "#         print(words)\n",
    "#         if conditionalProbabilitiesPosWithGroup[words][1] != encapsulated_groups[i][0]: # words not in conditionalProbabilitiesPosWithGroup:\n",
    "#             print('hi')\n",
    "\n",
    "print(conditionalProbabilitiesPosWithGroup['key'][1]) #== encapsulated_groups[i][0]: \n",
    "print(conditionalProbabilitiesPosWithGroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Happy': {'Joy': 1, 'laughter': 32, 'love': 29, 'sunshine': 3, 'serenity': 33, 'contentment': 27, 'delight': 27, 'bliss': 25, 'exuberance': 1, 'jubilation': 26, 'euphoria': 26, 'enchantment': 1, 'harmony': 35, 'gratitude': 30, 'peace': 3, 'serendipity': 1, 'kindness': 29, 'compassion': 30, 'friendship': 1, 'family': 1, 'togetherness': 28, 'unity': 2, 'hope': 2, 'optimism': 2, 'giggles': 1, 'elation': 4, 'sparkle': 1, 'cuddles': 2, 'warmth': 26, 'beauty': 1, 'radiant': 27, 'excitement': 1, 'carefree': 2, 'wonder': 1, 'playfulness': 27, 'amazement': 1, 'comfort': 4, 'music': 1, 'affection': 25, 'sharing': 1, 'giving': 1, 'blossoming': 1, 'joyous': 2, 'lighthearted': 1, 'zest': 1, 'heartwarming': 2, 'daisies': 1, 'tranquility': 1, 'cozy': 1, 'uplifting': 1, 'sparkling': 1, 'inspiration': 1, 'precious': 1, 'cherished': 2, 'blessings': 2, 'happiness': 26, 'blissful': 1, 'celebration': 1, 'vibrant': 2, 'delightful': 1, 'magical': 1, 'wonderment': 1, 'grace': 1, 'fulfillment': 3, 'joyfulness': 7, 'jubilant': 1, 'cheer': 1, 'serene': 1, 'joy': 21, 'radiance': 1}, 'sad': {'Grief': 1, 'sorrow': 3, 'despair': 4, 'loneliness': 4, 'heartache': 4, 'anguish': 4, 'melancholy': 4, 'misery': 4, 'depression': 2, 'pain': 4, 'suffering': 6, 'loss': 2, 'tragedy': 6, 'tearful': 4, 'mourning': 2, 'weeping': 20, 'somber': 8, 'desolation': 6, 'forlorn': 2, 'brokenhearted': 4, 'dismal': 6, 'wretched': 2, 'despondency': 2, 'heartbreak': 2, 'regret': 2, 'isolation': 2, 'bleak': 4, 'downcast': 4, 'disheartened': 4, 'glum': 4, 'woeful': 4, 'dejected': 4, 'mournful': 26, 'dreary': 2, 'unhappy': 4, 'sorrowful': 32, 'downhearted': 6, 'tearyeyed': 2, 'disconsolate': 4, 'hopeless': 2, 'devastated': 2, 'blue': 4, 'bereaved': 2, 'morose': 4, 'melancholic': 4, 'desolate': 4, 'somberness': 2, 'mourn': 8, 'sorrowing': 2, 'griefstricken': 8, 'inconsolable': 2, 'crestfallen': 2, 'pained': 4, 'tormented': 8, 'heavyhearted': 4, 'dark': 4, 'despondent': 2, 'lowspirited': 4, 'rueful': 4, 'hurt': 4, 'down': 2, 'anguished': 4, 'woebegone': 4, 'gloomy': 4, 'broken': 4, 'hurting': 6, 'sorrowfilled': 4, 'heartrending': 6, 'regretful': 4, 'cheerless': 4, 'lament': 2, 'traumatic': 2, 'heartwrenching': 2, 'bitter': 4, 'dreariness': 2, 'lamentable': 2, 'weep': 2, 'aching': 22, 'sobbing': 2, 'pitiful': 2, 'soulcrushing': 2, 'disheartenment': 2, 'bleakness': 2, 'anguishing': 2, 'depressive': 2, 'bereft': 2, 'tearjerking': 2, 'painful': 4, 'sorrowed': 2, 'mournfully': 4, 'melancholia': 2, 'adversity': 4, 'darkness': 2, 'tears': 4, 'dispirited': 2, 'lamenting': 23, 'emotional': 4, 'torment': 2, 'brokenness': 2, 'agony': 2, 'wistful': 2, 'lonely': 2, 'grief': 2, 'tragic': 2, 'heartbroken': 19, 'grieving': 19, 'tearstained': 18, 'despairing': 18}, 'fear': {'Terror': 1, 'dread': 9, 'anxiety': 9, 'fright': 9, 'panic': 36, 'horror': 17, 'phobia': 9, 'alarm': 17, 'trepidation': 9, 'nightmare': 9, 'apprehension': 17, 'unease': 9, 'spinechilling': 9, 'terrorstricken': 9, 'petrified': 9, 'chilling': 9, 'terrifying': 9, 'spooky': 9, 'daunting': 9, 'hairraising': 9, 'shudder': 9, 'shiver': 9, 'petrifying': 18, 'creepy': 9, 'fearful': 9, 'ominous': 9, 'spinetingling': 9, 'ghastly': 9, 'panicstricken': 9, 'alarming': 9, 'eerie': 9, 'anxious': 9, 'shivering': 9, 'quivering': 9, 'startle': 9, 'shock': 9, 'attack': 9, 'horrified': 9, 'unsettling': 9, 'fearinducing': 9, 'disorder': 9, 'frightful': 9, 'cold': 9, 'sweat': 9, 'bloodcurdling': 9, 'jittery': 9, 'jumpy': 9, 'unnerving': 9, 'nervousness': 9, 'distress': 9, 'uneasiness': 9, 'agitation': 9, 'disquiet': 9, 'concern': 9, 'fearfulness': 9, 'consternation': 9, 'terror': 14}}\n",
      "{'total_count': 1705, 'Happy': 608, 'sad': 527, 'fear': 570}\n"
     ]
    }
   ],
   "source": [
    "# since we have all the groups and sentences from the user we now need to pass it through the naive basis classifier\n",
    "\n",
    "# below is copied code and then we will revise it\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# all our sentences and groups are stored in encapsulated_groups\n",
    "\n",
    "# instead of having each sentence group being named 1,2,3.. etc, instead tell the user to make the first word to be the group name.\n",
    "''' \n",
    "dictionary \n",
    "with  {word, [number of times it appears , group ]}\n",
    "{group, [word, # times it appears]}\n",
    "\n",
    "\n",
    "        dict[group[0]] = [word, group_count]\n",
    "        each group starts with the group name. \n",
    "\n",
    "        dictionary -> dictionary group -> word : count\n",
    "        group -> words with their count\n",
    "        at end count number of counts \n",
    "\n",
    "'''\n",
    "\n",
    "# ---------------------------------------------------\n",
    "\n",
    "\n",
    "len(encapsulated_groups) # number of groups\n",
    "# dict = {'key': [1, 'group name']}\n",
    "dict = {}#{'group name' : {'word', 0}}\n",
    "# group_count = 0 # another dictionary to store count?\n",
    "group_counts = {} # ?? i could either count the number of words in each group then add them up later  # should we lea\n",
    "group_counts[\"total_count\"] = 0\n",
    "\n",
    "\n",
    "for group in encapsulated_groups: \n",
    "    dict[group[0]] = {} # dict is a dictionary of groups\n",
    "    count = 0\n",
    "    for word in group:\n",
    "        if word == group[0]: # this skips the group title, not sure if we should skip the group title or keep it\n",
    "            continue\n",
    "        count += 1\n",
    "        if word not in dict[group[0]]:\n",
    "            dict[group[0]][word] =  1 # create new key value pair\n",
    "        else:\n",
    "            dict[group[0]][word] +=  1 # increment key value pair\n",
    "    \n",
    "    group_counts[group[0]] = count # stores count for specific group \n",
    "    group_counts[\"total_count\"] += count # both of these will be added together in the denominator # then we can implement the flag method \n",
    "                                         # we add the numerator because we already have that value, then when taking the test cases, if the word is found we run the denominator and put \n",
    "                                         # value into the function, calculating it and then storing it into a dictionary, removing the needs for flags i think but probably not\n",
    "\n",
    "\n",
    "\n",
    "print(dict)\n",
    "print(group_counts) # this is for the denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing outputs here\n",
    "# print(encapsulated_groups)\n",
    "def dontrun():\n",
    "    for group in encapsulated_groups: \n",
    "        dict[group[0]] = {} # dict is a dictionary of groups\n",
    "        for word in group:\n",
    "            if word not in dict[group[0]]:\n",
    "                dict[group[0]][word] =  1\n",
    "            else:\n",
    "                dict[group[0]][word] +=  1\n",
    "\n",
    "t = \"I\"  \n",
    "# word = 'I'\n",
    "# for word in t: \n",
    "# for group in dict:   \n",
    "#     print(dict[group[0]][word])\n",
    "\n",
    "\n",
    "# for group in dict:   \n",
    "#         print(dict[group])\n",
    "\n",
    "# print(dict['Positive']['I'])\n",
    "# print(dict)\n",
    "# print(group_counts)\n",
    "\n",
    "\n",
    "# print('\\ndict:\\n',dict)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Being': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'happy': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'is': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'a': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'state': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'of': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'profound': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'contentment': {'Happy': 0.012105490704712495, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'and': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'joy': {'Happy': 0.009511456982274102, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'that': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'emanates': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'from': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'within': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'Its': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'radiant': {'Happy': 0.012105490704712495, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'feeling': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'brightens': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'every': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'aspect': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'life': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'infusing': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'even': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'mundane': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'moments': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'with': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'sense': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'wonder': {'Happy': 0.0008646779074794639, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'fulfillment': {'Happy': 0.0017293558149589277, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'Happiness': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'the': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'gentle': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'hum': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'laughter': {'Happy': 0.014267185473411154, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'shared': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'loved': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'ones': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'warm': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'embrace': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'accomplishment': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'after': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'dedicated': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'effort': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'serene': {'Happy': 0.0008646779074794639, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'tranquility': {'Happy': 0.0008646779074794639, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'found': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'in': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'appreciating': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'beauty': {'Happy': 0.0008646779074794639, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'present': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'moment': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'positive': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'energy': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'fuels': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'motivation': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'enhances': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'relationships': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'fosters': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'resilience': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'face': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'challenges': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'Cultivating': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'happiness': {'Happy': 0.011673151750972763, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'involves': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'nurturing': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'gratitude': {'Happy': 0.01340250756593169, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'pursuing': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'passions': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'meaningful': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'connections': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'ultimately': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'leading': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'to': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'illuminated': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'by': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'an': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'inner': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'glow': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'radiates': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'both': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'oneself': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}, 'world': {'Happy': 0.00043233895373973193, 'sad': 0.00044802867383512545, 'fear': 0.00043956043956043956}}\n",
      "{'Happy': 0.13402507565931676, 'sad': 0.05107526881720422, 'fear': 0.05010989010989018}\n",
      "The sentence \"Being happy is a state of profound contentment and joy that emanates from within. It's a radiant feeling that brightens every aspect of life, infusing even mundane moments with a sense of wonder and fulfillment. Happiness is the gentle hum of laughter shared with loved ones, the warm embrace of accomplishment after dedicated effort, and the serene tranquility found in appreciating the beauty of the present moment. It's a positive energy that fuels motivation, enhances relationships, and fosters resilience in the face of challenges. Cultivating happiness involves nurturing gratitude, pursuing passions, and nurturing meaningful connections, ultimately leading to a life illuminated by an inner glow that radiates happiness to both oneself and the world.\" closely matches the group sad\n",
      "sad\n"
     ]
    }
   ],
   "source": [
    "# here we ask for the user to enter a sentence and we will place it in the most suitable group \n",
    "u_input = input(\"Enter a sentence you would like to compare\")\n",
    "# u_input = \"since it is warm out i am happy Positive\" # example user u_input \n",
    "og_input = u_input\n",
    "# clean\n",
    "translation_table = str.maketrans('','', string.punctuation) \n",
    "u_input = u_input.translate(translation_table).split()\n",
    "dict_values = {} # nested dict\n",
    " # dict_values = {word : {group : p-val}} # swap word and group\n",
    " # if you find the word in the dict then you get the group \n",
    "\n",
    "dict_group_values = {}\n",
    "\n",
    "\n",
    "# find the word inside of the group \n",
    "for word in u_input: \n",
    "    # if word in dict_values:\n",
    "    #     # numerator = dict_values[key]\n",
    "    #     numerator = dict_values[word][]\n",
    "    #     break\n",
    "    dict_values[word] = {}\n",
    "    for group in dict.keys(): # ?can we look through the groups without a for loop\n",
    "        if group not in dict_group_values: # initialize it before adding up values\n",
    "            dict_group_values[group] = 0\n",
    "        # print('group:',group)\n",
    "        if word in dict_values and group in dict_values[word]:\n",
    "            dict_group_values[group] += dict_values[word][group]\n",
    "        # numerator = dict_values[key]\n",
    "            # print(dict_values[word][group])\n",
    "            # print(dict_values[group])\n",
    "            # print('numerator:', numerator)\n",
    "            # break # ? \n",
    "            continue # skip everything under\n",
    "        if word in dict[group]:\n",
    "            # print('word in dict\\nword:',word,'\\ngroup:',group)\n",
    "            # print(word,'FOUND') # if found calc the numerator\n",
    "            #numerator = number of times word appears in group which is the key +1\n",
    "            numerator = dict[group][word] + 1\n",
    "        else:\n",
    "            # print(word,'NOT found') # if not found the numator is always 1 b/c laplace smoothig\n",
    "            numerator = 1\n",
    "        # put the numerator into dict_values with the word\n",
    "        # dict_values[word] = numerator  # only put it in the dictionary once we divide it by the denominator\n",
    "        # dict_values[word] = { group : numerator / (group_counts[group] + group_counts['total_count']) } # this format doesn't work because it overrides the previous word\n",
    "        \n",
    "        dict_values[word][group] = numerator / (group_counts[group] + group_counts['total_count']) # change to unique words\n",
    "\n",
    "        dict_group_values[group] += dict_values[word][group] # the value\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "# dict[group[0]] = {} \n",
    "# dict[group[0]][word] =  1\n",
    "# print(dict_values[group]) \n",
    "print(dict_values)\n",
    "print(dict_group_values)\n",
    "\n",
    "\n",
    "#     for group in dict:\n",
    "#         if word in dict:\n",
    "#             # do function and put it in new dict\n",
    "#             numerator = dict[group[0][word]]\n",
    "#         else: \n",
    "#             numerator = 1\n",
    "#         print(numerator)\n",
    "\n",
    "max_group = max(dict_group_values)#, key=dict_group_values.get)\n",
    "max_value = dict_group_values[max_group]\n",
    "print(\"The sentence\",'\"'+og_input+'\"',\"closely matches the group\",max_group)\n",
    "print(max_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence \"\"In yonder garden, where fair blooms conspire to outshine the sun's own radiance, love's tender whisper finds echo in every petal's delicate curve.\"\" closely matches the group HungerGames\n"
     ]
    }
   ],
   "source": [
    "# max_key = max(my_dict, key=my_dict.get)\n",
    "# max_value = my_dict[max_key]\n",
    "\n",
    "max_group = max(dict_group_values, key=dict_group_values.get)\n",
    "max_value = dict_group_values[max_group]\n",
    "\n",
    "# print(\"Key:\", max_group)      # most likely group\n",
    "# print(\"Max Value:\", max_value) # most likely groups value\n",
    "print(\"The sentence\",'\"'+og_input+'\"',\"closely matches the group\",max_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# print(dict)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# encapsulated_groups[0][0]\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# dict.keys()\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39minput\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "# print(dict)\n",
    "# encapsulated_groups[0][0]\n",
    "# dict.keys()\n",
    "input(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Positive': {'I': 5, 'am': 1, 'very': 1, 'happy': 1, 'today': 1, 'because': 1, 'it': 1, 'is': 1, 'sunny': 1}, 'Negative': {'super': 1, 'sad': 3, 'since': 1, 'theres': 1, 'a': 1, 'lot': 1, 'of': 1, 'cold': 1, 'and': 1, 'rain': 1}, 'since': {}}\n"
     ]
    }
   ],
   "source": [
    "for word in input: \n",
    "    # if word in dict_values:\n",
    "    #     # numerator = dict_values[key]\n",
    "    #     numerator = dict_values[word][]\n",
    "    #     break\n",
    "    dict_values[word] = {}\n",
    "\n",
    "    for group in dict.keys():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# testing if functions update values even though theyre not returned # delete\n",
    "# x = 100\n",
    "\n",
    "# def double_x(r):\n",
    "#     x *= 2\n",
    "#     r +=  5\n",
    "#     return r\n",
    "\n",
    "# print('should print 405',double_x(400))\n",
    "# print('should print 200',x)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____\n",
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Groups\n",
      "[['happy', 'fsjdkflsjdkl', 'dsfsklfsj', 'fkds'], ['sads', 'fksj', 'fdlkfnsdkl'], ['angry', 'dskfjsdalk', 'dsafkjlads', 'aklfasjdl']]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "encapsulated_groups = []\n",
    "\n",
    "def split_sentences(sentences, group):\n",
    "    group = []\n",
    "    translation_table = str.maketrans('','', string.punctuation) \n",
    "    group = sentences.translate(translation_table).split()\n",
    "    encapsulated_groups.append(group)\n",
    "\n",
    "def something():\n",
    "    error = True\n",
    "    while error == True:\n",
    "        num_of_sentence_groups = input(\"Enter the number of number groups you would like: \")\n",
    "        error = False\n",
    "        try:\n",
    "            num_of_sentence_groups = int(num_of_sentence_groups)\n",
    "            if num_of_sentence_groups < 1 or num_of_sentence_groups > 50:\n",
    "                print(\"Please enter a number greater than 2 or less than 50\")\n",
    "                error = True\n",
    "        except ValueError:\n",
    "            num_of_sentence_groups = print(\"Please enter a valid number\")\n",
    "            error = True\n",
    "    print(num_of_sentence_groups,\"Groups\")\n",
    "\n",
    "    sentence_groups_created = 0\n",
    "    while sentence_groups_created < num_of_sentence_groups:\n",
    "        sentences = input(\"Train me by giving me sentences. Remember the more sentences, the more accurate I will be.\")\n",
    "        split_sentences(sentences, f\"group{sentence_groups_created}\")\n",
    "        sentence_groups_created += 1\n",
    "\n",
    "something()\n",
    "print(encapsulated_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'happy': {'fsjdkflsjdkl': 1, 'dsfsklfsj': 1, 'fkds': 1}, 'sads': {'fksj': 1, 'fdlkfnsdkl': 1}, 'angry': {'dskfjsdalk': 1, 'dsafkjlads': 1, 'aklfasjdl': 1}}\n",
      "{'total_count': 8, 'happy': 3, 'sads': 2, 'angry': 3}\n"
     ]
    }
   ],
   "source": [
    "len(encapsulated_groups)\n",
    "dict = {}\n",
    "group_counts = {}\n",
    "group_counts[\"total_count\"] = 0\n",
    "\n",
    "for group in encapsulated_groups:\n",
    "    dict[group[0]] = {}\n",
    "    count = 0\n",
    "    for word in group:\n",
    "        if word == group[0]:\n",
    "            continue\n",
    "        count += 1\n",
    "        if word not in dict[group[0]]:\n",
    "            dict[group[0]][word] = 1\n",
    "        else:\n",
    "            dict[group[0]][word] += 1\n",
    "    \n",
    "    group_counts[group[0]] = count\n",
    "    group_counts[\"total_count\"] += count\n",
    "\n",
    "print(dict)\n",
    "print(group_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence \"dskfjsdalk\" closely matches the group sads\n",
      "sads\n"
     ]
    }
   ],
   "source": [
    "u_input = input(\"Enter a sentence you would like to compare\")\n",
    "og_input = u_input\n",
    "translation_table = str.maketrans('','', string.punctuation) \n",
    "u_input = u_input.translate(translation_table).split()\n",
    "dict_values = {}\n",
    "dict_group_values = {}\n",
    "\n",
    "for word in u_input: \n",
    "    dict_values[word] = {}\n",
    "    for group in dict.keys():\n",
    "        if group not in dict_group_values:\n",
    "            dict_group_values[group] = 0\n",
    "        if word in dict_values and group in dict_values[word]:\n",
    "            dict_group_values[group] += dict_values[word][group]\n",
    "            continue\n",
    "        if word in dict[group]:\n",
    "            numerator = dict[group][word] + 1\n",
    "        else:\n",
    "            numerator = 1\n",
    "        dict_values[word][group] = numerator / (group_counts[group] + group_counts['total_count'])\n",
    "        dict_group_values[group] += dict_values[word][group]\n",
    "\n",
    "max_group = max(dict_group_values)\n",
    "max_value = dict_group_values[max_group]\n",
    "print(\"The sentence\",'\"'+og_input+'\"',\"closely matches the group\",max_group)\n",
    "print(max_group)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
